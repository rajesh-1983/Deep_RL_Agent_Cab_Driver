{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this case agent we use model architecture for which we input only state and output is q_value of every possible action.\n",
    "The advantage of this is just giving state as input state-value NN approximator function. We get output q_value for every possible action from this state. Here we have to run NN once for every state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_model = 'save_model'\n",
    "directory_pickle_files = 'saved_pickle_files'\n",
    "\n",
    "if not os.path.exists(directory_model):\n",
    "    os.makedirs(directory_model)\n",
    "    \n",
    "if not os.path.exists(directory_pickle_files):\n",
    "    os.makedirs(directory_pickle_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "States_track = collections.defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise states to be tracked\n",
    "def initialise_tracking_states():\n",
    "    sample_q_values = [((0, 6, 4), (0, 3)), ((0, 2, 1), (0, 4)), ((3, 22, 4), (2, 4)), ((1, 9, 1), (4, 0)), \n",
    "                       ((2, 20, 4), (3, 2)), ((2, 14, 1), (2, 4)), ((2, 14, 1), (0, 4)), ((3, 22, 4), (0, 4)),\n",
    "                       ((2, 13, 4), (4, 2)), ((4, 23, 6), (2, 4)), ((3, 22, 6), (0, 4)), ((1, 9, 2), (0, 0)),\n",
    "                       ((1, 11, 3), (1, 3)), ((0, 19, 4), (4, 1)), ((1, 23, 6), (2, 4))]\n",
    "  \n",
    "    for q_values in sample_q_values:\n",
    "        state_val = q_values[0]\n",
    "        action_val = q_values[1]\n",
    "        # Initialize q-values and state\n",
    "        States_track[state_val][action_val] = [] # This is an array which will have appended values of that state-action pair for every 2000th episode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function will be called end of every episode\n",
    "def save_tracking_states(agent, env):\n",
    "    for state_val in States_track.keys():\n",
    "        for action_val in States_track[state_val].keys():\n",
    "            input_data = env.state_encode_arch1(np.array(state_val))\n",
    "            q_value = agent.model.predict(input_data)\n",
    "            States_track[state_val][action_val].append(np.argmax(q_value[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, learning_rate=0.001, discount_factor=0.95, epsilon_decay=0.01, epsilon_min=0.001):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate =  learning_rate\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_max = 1\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self): \n",
    "        # The input The state space is defined by \n",
    "        # the driver’s current location along with the time components (hour-of-the-day and the day-of-the-week).\n",
    "        input_shape = self.state_size\n",
    "        \n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        \n",
    "        model.add(Dense(32, input_dim=input_shape, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        # The output layer output of size of action_space\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    "    def get_action(self, state, env, episode_time):\n",
    "        # get action from model using epsilon-greedy policy\n",
    "        # Decay in ε after we generate each sample from the environment\n",
    "        action = None\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # get possible action space for state\n",
    "            actions = env.requests(state)\n",
    "            action_index = np.random.choice(range(len(actions)))\n",
    "            action = actions[action_index]\n",
    "        else:\n",
    "            #choose action index with highest q(s, a)\n",
    "            input_state = env.state_encode_arch1(state)\n",
    "            q_value = self.model.predict(input_state)\n",
    "            action_index = np.argmax(q_value[0])\n",
    "            action = env.action_space[action_index]\n",
    "        \n",
    "        # epsilon decay\n",
    "        self.epsilon = self.epsilon_min + (self.epsilon_max - self.epsilon_min) * np.exp(-self.epsilon_decay*episode_time)\n",
    "        \n",
    "        return action\n",
    " \n",
    "\n",
    "    def append_sample(self, state, action_index, reward, next_state, terminal_state):\n",
    "        # Write your code here:\n",
    "        # save sample <s,a,r,s', terminal_state> to the replay memory\n",
    "        self.memory.append((state, action_index, reward, next_state, terminal_state))\n",
    "      \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self, env):\n",
    "        \n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))\n",
    "            \n",
    "            action_indices, rewards, terminal_states  = [], [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action_index, reward, next_state, terminal_state = mini_batch[i]\n",
    "                \n",
    "                # Write your code from here\n",
    "                update_input[i] = env.state_encode_arch1(state)\n",
    "                action_indices.append(action_index)\n",
    "                rewards.append(reward)\n",
    "                terminal_states.append(terminal_state)\n",
    "                update_output[i] = env.state_encode_arch1(next_state)\n",
    "                \n",
    "            # 1. Predict the target from earlier model\n",
    "            target = self.model.predict(update_input)\n",
    "            \n",
    "            # 2. Get the target for the Q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "\n",
    "            #3. Update your 'update_output' and 'update_input' batch\n",
    "            for i in range(self.batch_size):\n",
    "                # Q Learning: get maximum Q value at s' from target model\n",
    "                if terminal_states[i]:\n",
    "                    target[i][action_indices[i]] = rewards[i]\n",
    "                else:\n",
    "                    target[i][action_indices[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "                \n",
    "                \n",
    "            # 4. Fit your model and track the loss values\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "\n",
    "\n",
    "    def save_model_weights(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                1184      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 21)                693       \n",
      "=================================================================\n",
      "Total params: 2,933\n",
      "Trainable params: 2,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Episodes = 1000\n",
    "total_hours_duration = 720 #30 * 24 hours\n",
    "env = CabDriver(time_matrix)\n",
    "state_size = env.state_size\n",
    "action_size = len(env.action_space)\n",
    "\n",
    "#Call the DQN agent\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "rewards_per_episode= []\n",
    "\n",
    "tracking_threshold = 50\n",
    "# If driver drives continueously the maximum reward he can get in 30 days window is 720 * 9 - 720 * 5\n",
    "# total per hour cost - total fuel cost\n",
    "# we can stop traing if recent 20 epsiodes rewards reaches 95% of max_possible_reward\n",
    "max_possible_reward = 720*9 - 720*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, Agent ride Start_state (1, 16, 1), reward 0.0, memory_length 147, epsilon 1.0\n",
      "episode 1, Agent ride Start_state (2, 21, 3), reward -42.0, memory_length 296, epsilon 0.9900597839154189\n",
      "episode 2, Agent ride Start_state (4, 2, 4), reward -70.0, memory_length 448, epsilon 0.9802184746334485\n",
      "episode 3, Agent ride Start_state (0, 18, 2), reward -24.0, memory_length 577, epsilon 0.9704750880149596\n",
      "episode 4, Agent ride Start_state (0, 1, 5), reward -231.0, memory_length 720, epsilon 0.9608286497131708\n",
      "episode 5, Agent ride Start_state (4, 9, 1), reward 139.0, memory_length 860, epsilon 0.9512781950762133\n",
      "episode 6, Agent ride Start_state (3, 7, 5), reward -95.0, memory_length 997, epsilon 0.9418227690506644\n",
      "episode 7, Agent ride Start_state (4, 3, 1), reward -3.0, memory_length 1129, epsilon 0.9324614260860423\n",
      "episode 8, Agent ride Start_state (4, 11, 3), reward -127.0, memory_length 1263, epsilon 0.9231932300402491\n",
      "episode 9, Agent ride Start_state (2, 18, 6), reward -128.0, memory_length 1400, epsilon 0.9140172540859569\n",
      "episode 10, Agent ride Start_state (4, 18, 6), reward -56.0, memory_length 1538, epsilon 0.9049325806179236\n",
      "episode 11, Agent ride Start_state (0, 18, 3), reward 45.0, memory_length 1677, epsilon 0.8959383011612317\n",
      "episode 12, Agent ride Start_state (4, 22, 5), reward -278.0, memory_length 1799, epsilon 0.8870335162804404\n",
      "episode 13, Agent ride Start_state (4, 23, 0), reward 79.0, memory_length 1933, epsilon 0.8782173354896408\n",
      "episode 14, Agent ride Start_state (3, 4, 4), reward 90.0, memory_length 2000, epsilon 0.8694888771634071\n",
      "episode 15, Agent ride Start_state (1, 19, 2), reward 383.0, memory_length 2000, epsilon 0.8608472684486328\n",
      "episode 16, Agent ride Start_state (2, 10, 3), reward 85.0, memory_length 2000, epsilon 0.8522916451772451\n",
      "episode 17, Agent ride Start_state (4, 18, 2), reward 210.0, memory_length 2000, epsilon 0.8438211517797873\n",
      "episode 18, Agent ride Start_state (0, 2, 1), reward -57.0, memory_length 2000, epsilon 0.8354349411998607\n",
      "episode 19, Agent ride Start_state (4, 8, 1), reward 31.0, memory_length 2000, epsilon 0.8271321748094189\n",
      "episode 20, Agent ride Start_state (4, 13, 1), reward 409.0, memory_length 2000, epsilon 0.8189120223249038\n",
      "episode 21, Agent ride Start_state (3, 22, 4), reward 39.0, memory_length 2000, epsilon 0.8107736617242169\n",
      "episode 22, Agent ride Start_state (0, 7, 3), reward -53.0, memory_length 2000, epsilon 0.802716279164516\n",
      "episode 23, Agent ride Start_state (2, 20, 5), reward 239.0, memory_length 2000, epsilon 0.7947390689008307\n",
      "episode 24, Agent ride Start_state (3, 7, 1), reward 346.0, memory_length 2000, epsilon 0.7868412332054869\n",
      "episode 25, Agent ride Start_state (4, 1, 1), reward 317.0, memory_length 2000, epsilon 0.7790219822883335\n",
      "episode 26, Agent ride Start_state (3, 0, 3), reward 0.0, memory_length 2000, epsilon 0.7712805342177627\n",
      "episode 27, Agent ride Start_state (2, 3, 0), reward 156.0, memory_length 2000, epsilon 0.7636161148425163\n",
      "episode 28, Agent ride Start_state (1, 22, 1), reward 162.0, memory_length 2000, epsilon 0.7560279577142698\n",
      "episode 29, Agent ride Start_state (3, 3, 0), reward 592.0, memory_length 2000, epsilon 0.7485153040109868\n",
      "episode 30, Agent ride Start_state (1, 14, 1), reward 786.0, memory_length 2000, epsilon 0.7410774024610361\n",
      "episode 31, Agent ride Start_state (3, 15, 1), reward 634.0, memory_length 2000, epsilon 0.733713509268065\n",
      "episode 32, Agent ride Start_state (4, 6, 5), reward 297.0, memory_length 2000, epsilon 0.7264228880366173\n",
      "episode 33, Agent ride Start_state (4, 23, 0), reward 485.0, memory_length 2000, epsilon 0.7192048096984942\n",
      "episode 34, Agent ride Start_state (1, 3, 2), reward 520.0, memory_length 2000, epsilon 0.7120585524398471\n",
      "episode 35, Agent ride Start_state (2, 13, 0), reward 537.0, memory_length 2000, epsilon 0.7049834016289948\n",
      "episode 36, Agent ride Start_state (4, 0, 6), reward 307.0, memory_length 2000, epsilon 0.69797864974496\n",
      "episode 37, Agent ride Start_state (1, 3, 1), reward 313.0, memory_length 2000, epsilon 0.6910435963067173\n",
      "episode 38, Agent ride Start_state (0, 23, 3), reward 610.0, memory_length 2000, epsilon 0.6841775478031434\n",
      "episode 39, Agent ride Start_state (1, 0, 2), reward 720.0, memory_length 2000, epsilon 0.6773798176236665\n",
      "episode 40, Agent ride Start_state (2, 8, 5), reward 535.0, memory_length 2000, epsilon 0.6706497259896037\n",
      "episode 41, Agent ride Start_state (3, 4, 5), reward 344.0, memory_length 2000, epsilon 0.663986599886183\n",
      "episode 42, Agent ride Start_state (3, 4, 3), reward 891.0, memory_length 2000, epsilon 0.6573897729952417\n",
      "episode 43, Agent ride Start_state (2, 13, 2), reward 578.0, memory_length 2000, epsilon 0.6508585856285932\n",
      "episode 44, Agent ride Start_state (1, 22, 1), reward 1131.0, memory_length 2000, epsilon 0.6443923846620583\n",
      "episode 45, Agent ride Start_state (3, 18, 0), reward 975.0, memory_length 2000, epsilon 0.6379905234701515\n",
      "episode 46, Agent ride Start_state (3, 17, 1), reward 983.0, memory_length 2000, epsilon 0.631652361861419\n",
      "episode 47, Agent ride Start_state (0, 0, 6), reward 585.0, memory_length 2000, epsilon 0.6253772660144181\n",
      "episode 48, Agent ride Start_state (1, 15, 6), reward 860.0, memory_length 2000, epsilon 0.6191646084143347\n",
      "episode 49, Agent ride Start_state (4, 23, 5), reward 744.0, memory_length 2000, epsilon 0.6130137677902316\n",
      "episode 50, Agent ride Start_state (3, 0, 4), reward 620.0, memory_length 2000, epsilon 0.6069241290529208\n",
      "episode 51, Agent ride Start_state (2, 12, 2), reward 953.0, memory_length 2000, epsilon 0.6008950832334536\n",
      "episode 52, Agent ride Start_state (4, 15, 4), reward 1071.0, memory_length 2000, epsilon 0.5949260274222242\n",
      "episode 53, Agent ride Start_state (0, 2, 5), reward 1004.0, memory_length 2000, epsilon 0.5890163647086768\n",
      "episode 54, Agent ride Start_state (1, 6, 1), reward 920.0, memory_length 2000, epsilon 0.5831655041216156\n",
      "episode 55, Agent ride Start_state (4, 0, 3), reward 813.0, memory_length 2000, epsilon 0.5773728605701062\n",
      "episode 56, Agent ride Start_state (4, 20, 2), reward 941.0, memory_length 2000, epsilon 0.5716378547849661\n",
      "episode 57, Agent ride Start_state (3, 20, 6), reward 1191.0, memory_length 2000, epsilon 0.5659599132608375\n",
      "episode 58, Agent ride Start_state (4, 12, 0), reward 884.0, memory_length 2000, epsilon 0.5603384681988366\n",
      "episode 59, Agent ride Start_state (2, 3, 2), reward 825.0, memory_length 2000, epsilon 0.5547729574497726\n",
      "episode 60, Agent ride Start_state (2, 12, 1), reward 759.0, memory_length 2000, epsilon 0.5492628244579325\n",
      "episode 61, Agent ride Start_state (4, 11, 5), reward 835.0, memory_length 2000, epsilon 0.5438075182054253\n",
      "episode 62, Agent ride Start_state (3, 15, 6), reward 948.0, memory_length 2000, epsilon 0.5384064931570798\n",
      "episode 63, Agent ride Start_state (1, 22, 1), reward 937.0, memory_length 2000, epsilon 0.5330592092058903\n",
      "episode 64, Agent ride Start_state (3, 11, 1), reward 1120.0, memory_length 2000, epsilon 0.5277651316190055\n",
      "episode 65, Agent ride Start_state (1, 3, 1), reward 981.0, memory_length 2000, epsilon 0.522523730984255\n",
      "episode 66, Agent ride Start_state (4, 17, 6), reward 886.0, memory_length 2000, epsilon 0.5173344831572074\n",
      "episode 67, Agent ride Start_state (4, 5, 0), reward 1053.0, memory_length 2000, epsilon 0.5121968692087558\n",
      "episode 68, Agent ride Start_state (0, 17, 4), reward 1242.0, memory_length 2000, epsilon 0.507110375373224\n",
      "episode 69, Agent ride Start_state (2, 9, 6), reward 1277.0, memory_length 2000, epsilon 0.5020744929969894\n",
      "episode 70, Agent ride Start_state (0, 5, 1), reward 711.0, memory_length 2000, epsilon 0.49708871848761804\n",
      "episode 71, Agent ride Start_state (2, 21, 1), reward 1197.0, memory_length 2000, epsilon 0.49215255326350416\n",
      "episode 72, Agent ride Start_state (2, 22, 3), reward 873.0, memory_length 2000, epsilon 0.4872655037040117\n",
      "episode 73, Agent ride Start_state (1, 4, 0), reward 1300.0, memory_length 2000, epsilon 0.48242708110011223\n",
      "episode 74, Agent ride Start_state (4, 15, 4), reward 1098.0, memory_length 2000, epsilon 0.47763680160551336\n",
      "episode 75, Agent ride Start_state (3, 6, 4), reward 849.0, memory_length 2000, epsilon 0.47289418618827367\n",
      "episode 76, Agent ride Start_state (4, 14, 0), reward 1352.0, memory_length 2000, epsilon 0.46819876058289933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 77, Agent ride Start_state (2, 23, 3), reward 1353.0, memory_length 2000, epsilon 0.46355005524291687\n",
      "episode 78, Agent ride Start_state (4, 16, 4), reward 971.0, memory_length 2000, epsilon 0.4589476052939183\n",
      "episode 79, Agent ride Start_state (4, 8, 6), reward 1308.0, memory_length 2000, epsilon 0.45439095048707345\n",
      "episode 80, Agent ride Start_state (4, 16, 1), reward 1323.0, memory_length 2000, epsilon 0.44987963515310436\n",
      "episode 81, Agent ride Start_state (1, 5, 4), reward 1434.0, memory_length 2000, epsilon 0.44541320815671814\n",
      "episode 82, Agent ride Start_state (3, 11, 3), reward 1453.0, memory_length 2000, epsilon 0.4409912228514932\n",
      "episode 83, Agent ride Start_state (1, 7, 1), reward 1416.0, memory_length 2000, epsilon 0.43661323703521404\n",
      "episode 84, Agent ride Start_state (0, 13, 6), reward 1028.0, memory_length 2000, epsilon 0.4322788129056506\n",
      "episode 85, Agent ride Start_state (0, 11, 0), reward 1791.0, memory_length 2000, epsilon 0.427987517016778\n",
      "episode 86, Agent ride Start_state (0, 9, 3), reward 1466.0, memory_length 2000, epsilon 0.4237389202354311\n",
      "episode 87, Agent ride Start_state (3, 23, 6), reward 1557.0, memory_length 2000, epsilon 0.41953259769839135\n",
      "episode 88, Agent ride Start_state (0, 10, 1), reward 1835.0, memory_length 2000, epsilon 0.4153681287698998\n",
      "episode 89, Agent ride Start_state (2, 20, 4), reward 1782.0, memory_length 2000, epsilon 0.41124509699959316\n",
      "episode 90, Agent ride Start_state (0, 0, 6), reward 1365.0, memory_length 2000, epsilon 0.4071630900808585\n",
      "episode 91, Agent ride Start_state (2, 18, 0), reward 1659.0, memory_length 2000, epsilon 0.40312169980960233\n",
      "episode 92, Agent ride Start_state (4, 5, 4), reward 1745.0, memory_length 2000, epsilon 0.3991205220434296\n",
      "episode 93, Agent ride Start_state (2, 5, 3), reward 958.0, memory_length 2000, epsilon 0.39515915666122947\n",
      "episode 94, Agent ride Start_state (0, 9, 5), reward 1818.0, memory_length 2000, epsilon 0.39123720752316254\n",
      "episode 95, Agent ride Start_state (4, 16, 2), reward 1864.0, memory_length 2000, epsilon 0.3873542824310467\n",
      "episode 96, Agent ride Start_state (1, 20, 0), reward 1654.0, memory_length 2000, epsilon 0.38350999308913697\n",
      "episode 97, Agent ride Start_state (4, 2, 1), reward 1745.0, memory_length 2000, epsilon 0.3797039550652954\n",
      "episode 98, Agent ride Start_state (4, 3, 2), reward 1118.0, memory_length 2000, epsilon 0.37593578775254816\n",
      "episode 99, Agent ride Start_state (4, 2, 0), reward 1588.0, memory_length 2000, epsilon 0.37220511433102366\n",
      "episode 100, Agent ride Start_state (4, 4, 5), reward 1316.0, memory_length 2000, epsilon 0.3685115617302709\n",
      "episode 101, Agent ride Start_state (2, 1, 3), reward 1547.0, memory_length 2000, epsilon 0.3648547605919518\n",
      "episode 102, Agent ride Start_state (3, 6, 4), reward 1693.0, memory_length 2000, epsilon 0.3612343452329052\n",
      "episode 103, Agent ride Start_state (1, 19, 0), reward 1777.0, memory_length 2000, epsilon 0.3576499536085782\n",
      "episode 104, Agent ride Start_state (4, 4, 1), reward 1485.0, memory_length 2000, epsilon 0.35410122727682136\n",
      "episode 105, Agent ride Start_state (0, 20, 2), reward 1803.0, memory_length 2000, epsilon 0.3505878113620442\n",
      "episode 106, Agent ride Start_state (4, 2, 2), reward 1495.0, memory_length 2000, epsilon 0.34710935451972735\n",
      "episode 107, Agent ride Start_state (2, 0, 6), reward 1556.0, memory_length 2000, epsilon 0.34366550890128794\n",
      "episode 108, Agent ride Start_state (1, 15, 4), reward 1246.0, memory_length 2000, epsilon 0.34025593011929417\n",
      "episode 109, Agent ride Start_state (0, 0, 1), reward 1779.0, memory_length 2000, epsilon 0.3368802772130266\n",
      "episode 110, Agent ride Start_state (1, 20, 4), reward 1809.0, memory_length 2000, epsilon 0.3335382126143815\n",
      "episode 111, Agent ride Start_state (3, 1, 4), reward 1652.0, memory_length 2000, epsilon 0.3302294021141139\n",
      "episode 112, Agent ride Start_state (0, 14, 1), reward 1988.0, memory_length 2000, epsilon 0.32695351482841645\n",
      "episode 113, Agent ride Start_state (4, 17, 4), reward 1584.0, memory_length 2000, epsilon 0.32371022316583065\n",
      "episode 114, Agent ride Start_state (0, 13, 2), reward 1807.0, memory_length 2000, epsilon 0.3204992027944875\n",
      "episode 115, Agent ride Start_state (2, 2, 2), reward 2207.0, memory_length 2000, epsilon 0.3173201326096741\n",
      "episode 116, Agent ride Start_state (1, 15, 0), reward 1699.0, memory_length 2000, epsilon 0.3141726947017227\n",
      "episode 117, Agent ride Start_state (4, 23, 6), reward 2172.0, memory_length 2000, epsilon 0.31105657432421957\n",
      "episode 118, Agent ride Start_state (0, 3, 2), reward 2202.0, memory_length 2000, epsilon 0.3079714598625301\n",
      "episode 119, Agent ride Start_state (2, 16, 6), reward 1969.0, memory_length 2000, epsilon 0.3049170428026374\n",
      "episode 120, Agent ride Start_state (4, 4, 6), reward 1926.0, memory_length 2000, epsilon 0.3018930177002899\n",
      "episode 121, Agent ride Start_state (3, 7, 6), reward 1930.0, memory_length 2000, epsilon 0.2988990821504575\n",
      "episode 122, Agent ride Start_state (1, 21, 6), reward 1727.0, memory_length 2000, epsilon 0.2959349367570902\n",
      "episode 123, Agent ride Start_state (1, 12, 3), reward 1966.0, memory_length 2000, epsilon 0.29300028510317855\n",
      "episode 124, Agent ride Start_state (4, 22, 3), reward 1630.0, memory_length 2000, epsilon 0.29009483372111156\n",
      "episode 125, Agent ride Start_state (0, 20, 1), reward 1723.0, memory_length 2000, epsilon 0.2872182920633299\n",
      "episode 126, Agent ride Start_state (0, 4, 2), reward 2077.0, memory_length 2000, epsilon 0.2843703724732706\n",
      "episode 127, Agent ride Start_state (1, 12, 2), reward 1849.0, memory_length 2000, epsilon 0.2815507901566014\n",
      "episode 128, Agent ride Start_state (3, 13, 4), reward 2000.0, memory_length 2000, epsilon 0.27875926315274097\n",
      "episode 129, Agent ride Start_state (2, 22, 3), reward 2146.0, memory_length 2000, epsilon 0.2759955123066626\n",
      "episode 130, Agent ride Start_state (3, 20, 5), reward 1854.0, memory_length 2000, epsilon 0.2732592612409786\n",
      "episode 131, Agent ride Start_state (1, 15, 2), reward 2141.0, memory_length 2000, epsilon 0.2705502363283021\n",
      "episode 132, Agent ride Start_state (0, 15, 0), reward 1852.0, memory_length 2000, epsilon 0.26786816666388447\n",
      "episode 133, Agent ride Start_state (4, 19, 2), reward 1916.0, memory_length 2000, epsilon 0.26521278403852416\n",
      "episode 134, Agent ride Start_state (4, 10, 2), reward 1485.0, memory_length 2000, epsilon 0.26258382291174565\n",
      "episode 135, Agent ride Start_state (1, 3, 3), reward 1893.0, memory_length 2000, epsilon 0.2599810203852456\n",
      "episode 136, Agent ride Start_state (1, 23, 5), reward 1862.0, memory_length 2000, epsilon 0.2574041161766023\n",
      "episode 137, Agent ride Start_state (2, 18, 2), reward 2018.0, memory_length 2000, epsilon 0.25485285259324747\n",
      "episode 138, Agent ride Start_state (1, 19, 4), reward 1938.0, memory_length 2000, epsilon 0.2523269745066967\n",
      "episode 139, Agent ride Start_state (4, 13, 3), reward 1827.0, memory_length 2000, epsilon 0.2498262293270365\n",
      "episode 140, Agent ride Start_state (2, 0, 6), reward 2074.0, memory_length 2000, epsilon 0.24735036697766483\n",
      "episode 141, Agent ride Start_state (1, 4, 4), reward 1847.0, memory_length 2000, epsilon 0.24489913987028367\n",
      "episode 142, Agent ride Start_state (1, 4, 2), reward 1772.0, memory_length 2000, epsilon 0.2424723028801394\n",
      "episode 143, Agent ride Start_state (0, 17, 2), reward 1424.0, memory_length 2000, epsilon 0.2400696133215108\n",
      "episode 144, Agent ride Start_state (1, 22, 2), reward 2157.0, memory_length 2000, epsilon 0.23769083092343965\n",
      "episode 145, Agent ride Start_state (2, 3, 1), reward 1944.0, memory_length 2000, epsilon 0.23533571780570386\n",
      "episode 146, Agent ride Start_state (1, 16, 2), reward 1849.0, memory_length 2000, epsilon 0.23300403845502907\n",
      "episode 147, Agent ride Start_state (0, 10, 6), reward 1817.0, memory_length 2000, epsilon 0.23069555970153713\n",
      "episode 148, Agent ride Start_state (0, 20, 4), reward 1978.0, memory_length 2000, epsilon 0.2284100506954289\n",
      "episode 149, Agent ride Start_state (4, 1, 4), reward 1662.0, memory_length 2000, epsilon 0.2261472828838993\n",
      "episode 150, Agent ride Start_state (4, 9, 5), reward 1897.0, memory_length 2000, epsilon 0.22390702998828138\n",
      "episode 151, Agent ride Start_state (4, 3, 6), reward 2095.0, memory_length 2000, epsilon 0.22168906798141882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 152, Agent ride Start_state (0, 2, 1), reward 1791.0, memory_length 2000, epsilon 0.21949317506526253\n",
      "episode 153, Agent ride Start_state (3, 4, 0), reward 2020.0, memory_length 2000, epsilon 0.21731913164869107\n",
      "episode 154, Agent ride Start_state (4, 17, 5), reward 2079.0, memory_length 2000, epsilon 0.21516672032555095\n",
      "episode 155, Agent ride Start_state (4, 22, 2), reward 2081.0, memory_length 2000, epsilon 0.2130357258529163\n",
      "episode 156, Agent ride Start_state (1, 23, 3), reward 2151.0, memory_length 2000, epsilon 0.21092593512956395\n",
      "episode 157, Agent ride Start_state (0, 19, 5), reward 2056.0, memory_length 2000, epsilon 0.20883713717466346\n",
      "episode 158, Agent ride Start_state (3, 5, 1), reward 2158.0, memory_length 2000, epsilon 0.20676912310667855\n",
      "episode 159, Agent ride Start_state (4, 23, 2), reward 1974.0, memory_length 2000, epsilon 0.2047216861224792\n",
      "episode 160, Agent ride Start_state (0, 9, 6), reward 2407.0, memory_length 2000, epsilon 0.20269462147666073\n",
      "episode 161, Agent ride Start_state (0, 20, 2), reward 2220.0, memory_length 2000, epsilon 0.20068772646106936\n",
      "episode 162, Agent ride Start_state (3, 8, 0), reward 2063.0, memory_length 2000, epsilon 0.19870080038453103\n",
      "episode 163, Agent ride Start_state (2, 7, 3), reward 2193.0, memory_length 2000, epsilon 0.19673364455278244\n",
      "episode 164, Agent ride Start_state (3, 4, 3), reward 1947.0, memory_length 2000, epsilon 0.19478606224860098\n",
      "episode 165, Agent ride Start_state (2, 17, 1), reward 2101.0, memory_length 2000, epsilon 0.19285785871213332\n",
      "episode 166, Agent ride Start_state (0, 19, 5), reward 2071.0, memory_length 2000, epsilon 0.19094884112141897\n",
      "episode 167, Agent ride Start_state (1, 14, 4), reward 2162.0, memory_length 2000, epsilon 0.18905881857310805\n",
      "episode 168, Agent ride Start_state (3, 16, 6), reward 2220.0, memory_length 2000, epsilon 0.18718760206337057\n",
      "episode 169, Agent ride Start_state (1, 16, 0), reward 2288.0, memory_length 2000, epsilon 0.18533500446899628\n",
      "episode 170, Agent ride Start_state (4, 18, 6), reward 1971.0, memory_length 2000, epsilon 0.18350084052868193\n",
      "episode 171, Agent ride Start_state (3, 23, 1), reward 2134.0, memory_length 2000, epsilon 0.181684926824505\n",
      "episode 172, Agent ride Start_state (1, 11, 3), reward 2285.0, memory_length 2000, epsilon 0.17988708176358173\n",
      "episode 173, Agent ride Start_state (4, 22, 1), reward 2376.0, memory_length 2000, epsilon 0.17810712555990793\n",
      "episode 174, Agent ride Start_state (0, 14, 6), reward 2180.0, memory_length 2000, epsilon 0.17634488021637987\n",
      "episode 175, Agent ride Start_state (0, 1, 2), reward 2531.0, memory_length 2000, epsilon 0.1746001695069947\n",
      "episode 176, Agent ride Start_state (4, 14, 2), reward 1804.0, memory_length 2000, epsilon 0.1728728189592275\n",
      "episode 177, Agent ride Start_state (4, 16, 3), reward 1997.0, memory_length 2000, epsilon 0.17116265583658402\n",
      "episode 178, Agent ride Start_state (4, 6, 5), reward 2405.0, memory_length 2000, epsilon 0.1694695091213269\n",
      "episode 179, Agent ride Start_state (0, 1, 1), reward 2316.0, memory_length 2000, epsilon 0.16779320949737364\n",
      "episode 180, Agent ride Start_state (0, 4, 5), reward 2247.0, memory_length 2000, epsilon 0.16613358933336494\n",
      "episode 181, Agent ride Start_state (0, 16, 0), reward 2569.0, memory_length 2000, epsilon 0.16449048266590136\n",
      "episode 182, Agent ride Start_state (1, 22, 5), reward 2298.0, memory_length 2000, epsilon 0.16286372518294687\n",
      "episode 183, Agent ride Start_state (3, 0, 3), reward 2404.0, memory_length 2000, epsilon 0.16125315420739755\n",
      "episode 184, Agent ride Start_state (0, 13, 0), reward 2451.0, memory_length 2000, epsilon 0.15965860868081375\n",
      "episode 185, Agent ride Start_state (1, 9, 5), reward 2501.0, memory_length 2000, epsilon 0.15807992914731397\n",
      "episode 186, Agent ride Start_state (0, 0, 5), reward 2202.0, memory_length 2000, epsilon 0.1565169577376293\n",
      "episode 187, Agent ride Start_state (1, 19, 2), reward 2173.0, memory_length 2000, epsilon 0.15496953815331627\n",
      "episode 188, Agent ride Start_state (3, 12, 1), reward 2215.0, memory_length 2000, epsilon 0.15343751565112698\n",
      "episode 189, Agent ride Start_state (1, 1, 4), reward 2160.0, memory_length 2000, epsilon 0.15192073702753447\n",
      "episode 190, Agent ride Start_state (1, 2, 1), reward 2356.0, memory_length 2000, epsilon 0.1504190506034124\n",
      "episode 191, Agent ride Start_state (1, 3, 3), reward 2338.0, memory_length 2000, epsilon 0.14893230620886697\n",
      "episode 192, Agent ride Start_state (3, 21, 2), reward 2115.0, memory_length 2000, epsilon 0.14746035516821981\n",
      "episode 193, Agent ride Start_state (0, 1, 1), reward 2192.0, memory_length 2000, epsilon 0.1460030502851401\n",
      "episode 194, Agent ride Start_state (1, 7, 1), reward 2034.0, memory_length 2000, epsilon 0.14456024582792523\n",
      "episode 195, Agent ride Start_state (1, 9, 6), reward 2106.0, memory_length 2000, epsilon 0.14313179751492708\n",
      "episode 196, Agent ride Start_state (3, 4, 3), reward 2091.0, memory_length 2000, epsilon 0.14171756250012396\n",
      "episode 197, Agent ride Start_state (4, 13, 0), reward 2314.0, memory_length 2000, epsilon 0.1403173993588359\n",
      "episode 198, Agent ride Start_state (1, 20, 2), reward 2074.0, memory_length 2000, epsilon 0.13893116807358194\n",
      "episode 199, Agent ride Start_state (1, 11, 1), reward 2106.0, memory_length 2000, epsilon 0.13755873002007832\n",
      "episode 200, Agent ride Start_state (2, 21, 4), reward 2164.0, memory_length 2000, epsilon 0.1361999479533761\n",
      "episode 201, Agent ride Start_state (1, 17, 5), reward 2151.0, memory_length 2000, epsilon 0.13485468599413614\n",
      "episode 202, Agent ride Start_state (0, 17, 5), reward 2191.0, memory_length 2000, epsilon 0.1335228096150416\n",
      "episode 203, Agent ride Start_state (3, 1, 6), reward 2468.0, memory_length 2000, epsilon 0.13220418562734454\n",
      "episode 204, Agent ride Start_state (4, 4, 1), reward 2412.0, memory_length 2000, epsilon 0.1308986821675475\n",
      "episode 205, Agent ride Start_state (3, 12, 5), reward 2434.0, memory_length 2000, epsilon 0.12960616868421643\n",
      "episode 206, Agent ride Start_state (0, 9, 5), reward 2495.0, memory_length 2000, epsilon 0.12832651592492592\n",
      "episode 207, Agent ride Start_state (0, 6, 3), reward 2037.0, memory_length 2000, epsilon 0.12705959592333374\n",
      "episode 208, Agent ride Start_state (3, 17, 0), reward 2285.0, memory_length 2000, epsilon 0.12580528198638383\n",
      "episode 209, Agent ride Start_state (3, 15, 6), reward 2470.0, memory_length 2000, epsilon 0.12456344868163738\n",
      "episode 210, Agent ride Start_state (4, 1, 2), reward 2121.0, memory_length 2000, epsilon 0.12333397182472892\n",
      "episode 211, Agent ride Start_state (3, 14, 3), reward 2542.0, memory_length 2000, epsilon 0.1221167284669483\n",
      "episode 212, Agent ride Start_state (4, 12, 4), reward 2296.0, memory_length 2000, epsilon 0.12091159688294527\n",
      "episode 213, Agent ride Start_state (0, 6, 3), reward 2329.0, memory_length 2000, epsilon 0.11971845655855724\n",
      "episode 214, Agent ride Start_state (0, 6, 1), reward 2261.0, memory_length 2000, epsilon 0.1185371881787574\n",
      "episode 215, Agent ride Start_state (1, 20, 4), reward 2317.0, memory_length 2000, epsilon 0.11736767361572346\n",
      "episode 216, Agent ride Start_state (4, 18, 5), reward 2494.0, memory_length 2000, epsilon 0.11620979591702445\n",
      "episode 217, Agent ride Start_state (0, 23, 6), reward 2123.0, memory_length 2000, epsilon 0.11506343929392567\n",
      "episode 218, Agent ride Start_state (4, 9, 5), reward 2245.0, memory_length 2000, epsilon 0.11392848910980939\n",
      "episode 219, Agent ride Start_state (4, 22, 4), reward 2209.0, memory_length 2000, epsilon 0.11280483186871156\n",
      "episode 220, Agent ride Start_state (2, 13, 6), reward 2169.0, memory_length 2000, epsilon 0.11169235520397154\n",
      "episode 221, Agent ride Start_state (4, 15, 0), reward 2156.0, memory_length 2000, epsilon 0.1105909478669959\n",
      "episode 222, Agent ride Start_state (1, 3, 2), reward 2298.0, memory_length 2000, epsilon 0.109500499716133\n",
      "episode 223, Agent ride Start_state (3, 3, 4), reward 2342.0, memory_length 2000, epsilon 0.10842090170565916\n",
      "episode 224, Agent ride Start_state (0, 5, 6), reward 2299.0, memory_length 2000, epsilon 0.10735204587487356\n",
      "episode 225, Agent ride Start_state (4, 20, 4), reward 2324.0, memory_length 2000, epsilon 0.10629382533730247\n",
      "episode 226, Agent ride Start_state (2, 20, 4), reward 2541.0, memory_length 2000, epsilon 0.10524613427001023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 227, Agent ride Start_state (4, 4, 5), reward 2293.0, memory_length 2000, epsilon 0.1042088679030171\n",
      "episode 228, Agent ride Start_state (0, 5, 5), reward 2618.0, memory_length 2000, epsilon 0.1031819225088219\n",
      "episode 229, Agent ride Start_state (2, 7, 1), reward 2242.0, memory_length 2000, epsilon 0.10216519539202952\n",
      "episode 230, Agent ride Start_state (1, 8, 4), reward 2475.0, memory_length 2000, epsilon 0.1011585848790809\n",
      "episode 231, Agent ride Start_state (3, 16, 2), reward 2372.0, memory_length 2000, epsilon 0.10016199030808601\n",
      "episode 232, Agent ride Start_state (0, 20, 1), reward 2632.0, memory_length 2000, epsilon 0.09917531201875718\n",
      "episode 233, Agent ride Start_state (3, 8, 1), reward 2375.0, memory_length 2000, epsilon 0.09819845134244323\n",
      "episode 234, Agent ride Start_state (2, 13, 5), reward 2448.0, memory_length 2000, epsilon 0.09723131059226255\n",
      "episode 235, Agent ride Start_state (2, 13, 6), reward 2321.0, memory_length 2000, epsilon 0.09627379305333407\n",
      "episode 236, Agent ride Start_state (0, 15, 1), reward 2608.0, memory_length 2000, epsilon 0.09532580297310604\n",
      "episode 237, Agent ride Start_state (2, 15, 1), reward 2501.0, memory_length 2000, epsilon 0.09438724555178041\n",
      "episode 238, Agent ride Start_state (3, 4, 0), reward 2627.0, memory_length 2000, epsilon 0.09345802693283295\n",
      "episode 239, Agent ride Start_state (3, 14, 5), reward 1975.0, memory_length 2000, epsilon 0.09253805419362733\n",
      "episode 240, Agent ride Start_state (3, 0, 2), reward 2375.0, memory_length 2000, epsilon 0.0916272353361231\n",
      "episode 241, Agent ride Start_state (4, 10, 1), reward 2297.0, memory_length 2000, epsilon 0.09072547927767538\n",
      "episode 242, Agent ride Start_state (4, 22, 6), reward 2167.0, memory_length 2000, epsilon 0.08983269584192696\n",
      "episode 243, Agent ride Start_state (0, 18, 5), reward 2353.0, memory_length 2000, epsilon 0.08894879574979017\n",
      "episode 244, Agent ride Start_state (3, 16, 0), reward 2307.0, memory_length 2000, epsilon 0.08807369061051931\n",
      "episode 245, Agent ride Start_state (2, 0, 6), reward 2378.0, memory_length 2000, epsilon 0.08720729291287113\n",
      "episode 246, Agent ride Start_state (0, 15, 0), reward 2500.0, memory_length 2000, epsilon 0.0863495160163539\n",
      "episode 247, Agent ride Start_state (2, 5, 3), reward 2313.0, memory_length 2000, epsilon 0.08550027414256313\n",
      "episode 248, Agent ride Start_state (2, 3, 4), reward 2243.0, memory_length 2000, epsilon 0.08465948236660377\n",
      "episode 249, Agent ride Start_state (1, 23, 5), reward 2500.0, memory_length 2000, epsilon 0.08382705660859749\n",
      "episode 250, Agent ride Start_state (0, 17, 2), reward 2277.0, memory_length 2000, epsilon 0.0830029136252749\n",
      "episode 251, Agent ride Start_state (0, 14, 5), reward 2308.0, memory_length 2000, epsilon 0.08218697100165079\n",
      "episode 252, Agent ride Start_state (0, 5, 3), reward 2213.0, memory_length 2000, epsilon 0.08137914714278291\n",
      "episode 253, Agent ride Start_state (1, 10, 5), reward 2106.0, memory_length 2000, epsilon 0.08057936126561212\n",
      "episode 254, Agent ride Start_state (0, 22, 5), reward 2415.0, memory_length 2000, epsilon 0.07978753339088428\n",
      "episode 255, Agent ride Start_state (0, 13, 5), reward 2267.0, memory_length 2000, epsilon 0.07900358433515198\n",
      "episode 256, Agent ride Start_state (1, 17, 1), reward 2349.0, memory_length 2000, epsilon 0.07822743570285644\n",
      "episode 257, Agent ride Start_state (1, 8, 3), reward 2249.0, memory_length 2000, epsilon 0.0774590098784876\n",
      "episode 258, Agent ride Start_state (4, 11, 2), reward 2514.0, memory_length 2000, epsilon 0.07669823001882263\n",
      "episode 259, Agent ride Start_state (2, 8, 0), reward 2504.0, memory_length 2000, epsilon 0.07594502004524165\n",
      "episode 260, Agent ride Start_state (2, 23, 0), reward 2487.0, memory_length 2000, epsilon 0.07519930463611954\n",
      "episode 261, Agent ride Start_state (0, 0, 4), reward 2563.0, memory_length 2000, epsilon 0.07446100921929404\n",
      "episode 262, Agent ride Start_state (0, 6, 5), reward 2338.0, memory_length 2000, epsilon 0.07373005996460816\n",
      "episode 263, Agent ride Start_state (2, 9, 0), reward 2362.0, memory_length 2000, epsilon 0.07300638377652734\n",
      "episode 264, Agent ride Start_state (2, 5, 3), reward 2495.0, memory_length 2000, epsilon 0.07228990828682967\n",
      "episode 265, Agent ride Start_state (2, 10, 1), reward 2582.0, memory_length 2000, epsilon 0.07158056184736916\n",
      "episode 266, Agent ride Start_state (0, 0, 3), reward 2404.0, memory_length 2000, epsilon 0.0708782735229107\n",
      "episode 267, Agent ride Start_state (4, 13, 5), reward 2370.0, memory_length 2000, epsilon 0.07018297308403665\n",
      "episode 268, Agent ride Start_state (4, 8, 2), reward 2671.0, memory_length 2000, epsilon 0.06949459100012363\n",
      "episode 269, Agent ride Start_state (1, 21, 6), reward 2533.0, memory_length 2000, epsilon 0.06881305843238968\n",
      "episode 270, Agent ride Start_state (3, 14, 3), reward 2604.0, memory_length 2000, epsilon 0.06813830722701\n",
      "episode 271, Agent ride Start_state (0, 9, 4), reward 2479.0, memory_length 2000, epsilon 0.06747026990830184\n",
      "episode 272, Agent ride Start_state (1, 7, 0), reward 2612.0, memory_length 2000, epsilon 0.06680887967197655\n",
      "episode 273, Agent ride Start_state (4, 14, 5), reward 2497.0, memory_length 2000, epsilon 0.0661540703784594\n",
      "episode 274, Agent ride Start_state (0, 6, 6), reward 2608.0, memory_length 2000, epsilon 0.0655057765462753\n",
      "episode 275, Agent ride Start_state (0, 11, 4), reward 2426.0, memory_length 2000, epsilon 0.06486393334550086\n",
      "episode 276, Agent ride Start_state (0, 9, 4), reward 2498.0, memory_length 2000, epsilon 0.06422847659128106\n",
      "episode 277, Agent ride Start_state (4, 16, 5), reward 2385.0, memory_length 2000, epsilon 0.063599342737411\n",
      "episode 278, Agent ride Start_state (3, 7, 5), reward 2538.0, memory_length 2000, epsilon 0.06297646886998093\n",
      "episode 279, Agent ride Start_state (4, 23, 3), reward 2304.0, memory_length 2000, epsilon 0.062359792701085125\n",
      "episode 280, Agent ride Start_state (0, 15, 2), reward 2623.0, memory_length 2000, epsilon 0.061749252562592734\n",
      "episode 281, Agent ride Start_state (3, 10, 5), reward 2568.0, memory_length 2000, epsilon 0.06114478739998117\n",
      "episode 282, Agent ride Start_state (4, 0, 3), reward 2540.0, memory_length 2000, epsilon 0.06054633676623043\n",
      "episode 283, Agent ride Start_state (0, 4, 2), reward 2371.0, memory_length 2000, epsilon 0.0599538408157784\n",
      "episode 284, Agent ride Start_state (2, 0, 6), reward 2362.0, memory_length 2000, epsilon 0.05936724029853633\n",
      "episode 285, Agent ride Start_state (3, 4, 4), reward 2340.0, memory_length 2000, epsilon 0.058786476553963615\n",
      "episode 286, Agent ride Start_state (4, 23, 2), reward 2671.0, memory_length 2000, epsilon 0.05821149150520189\n",
      "episode 287, Agent ride Start_state (3, 15, 4), reward 2429.0, memory_length 2000, epsilon 0.057642227653267056\n",
      "episode 288, Agent ride Start_state (4, 9, 2), reward 2457.0, memory_length 2000, epsilon 0.05707862807129959\n",
      "episode 289, Agent ride Start_state (1, 4, 4), reward 2298.0, memory_length 2000, epsilon 0.056520636398871574\n",
      "episode 290, Agent ride Start_state (3, 18, 6), reward 2364.0, memory_length 2000, epsilon 0.05596819683635083\n",
      "episode 291, Agent ride Start_state (1, 9, 3), reward 2450.0, memory_length 2000, epsilon 0.05542125413932067\n",
      "episode 292, Agent ride Start_state (4, 0, 4), reward 2403.0, memory_length 2000, epsilon 0.054879753613055665\n",
      "episode 293, Agent ride Start_state (0, 9, 0), reward 2293.0, memory_length 2000, epsilon 0.054343641107051886\n",
      "episode 294, Agent ride Start_state (4, 12, 1), reward 2407.0, memory_length 2000, epsilon 0.053812863009612015\n",
      "episode 295, Agent ride Start_state (1, 6, 3), reward 2338.0, memory_length 2000, epsilon 0.05328736624248395\n",
      "episode 296, Agent ride Start_state (3, 14, 2), reward 2299.0, memory_length 2000, epsilon 0.052767098255553105\n",
      "episode 297, Agent ride Start_state (1, 23, 4), reward 2526.0, memory_length 2000, epsilon 0.052252007021587187\n",
      "episode 298, Agent ride Start_state (1, 16, 4), reward 2502.0, memory_length 2000, epsilon 0.0517420410310336\n",
      "episode 299, Agent ride Start_state (3, 22, 3), reward 2596.0, memory_length 2000, epsilon 0.051237149286868275\n",
      "episode 300, Agent ride Start_state (4, 13, 2), reward 2258.0, memory_length 2000, epsilon 0.05073728129949608\n",
      "episode 301, Agent ride Start_state (4, 11, 4), reward 2300.0, memory_length 2000, epsilon 0.05024238708170169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 302, Agent ride Start_state (1, 20, 6), reward 2515.0, memory_length 2000, epsilon 0.04975241714365095\n",
      "episode 303, Agent ride Start_state (2, 9, 3), reward 2466.0, memory_length 2000, epsilon 0.0492673224879417\n",
      "episode 304, Agent ride Start_state (3, 0, 2), reward 2172.0, memory_length 2000, epsilon 0.04878705460470417\n",
      "episode 305, Agent ride Start_state (0, 12, 3), reward 2297.0, memory_length 2000, epsilon 0.048311565466749765\n",
      "episode 306, Agent ride Start_state (1, 23, 0), reward 2396.0, memory_length 2000, epsilon 0.0478408075247685\n",
      "episode 307, Agent ride Start_state (0, 16, 0), reward 2375.0, memory_length 2000, epsilon 0.04737473370257382\n",
      "episode 308, Agent ride Start_state (0, 23, 5), reward 2696.0, memory_length 2000, epsilon 0.04691329739239516\n",
      "episode 309, Agent ride Start_state (3, 9, 5), reward 2387.0, memory_length 2000, epsilon 0.04645645245021695\n",
      "episode 310, Agent ride Start_state (1, 20, 5), reward 2562.0, memory_length 2000, epsilon 0.04600415319116424\n",
      "episode 311, Agent ride Start_state (4, 1, 4), reward 2657.0, memory_length 2000, epsilon 0.04555635438493426\n",
      "episode 312, Agent ride Start_state (3, 13, 6), reward 2522.0, memory_length 2000, epsilon 0.04511301125127317\n",
      "episode 313, Agent ride Start_state (4, 4, 5), reward 2653.0, memory_length 2000, epsilon 0.04467407945549819\n",
      "episode 314, Agent ride Start_state (0, 9, 3), reward 2688.0, memory_length 2000, epsilon 0.04423951510406393\n",
      "episode 315, Agent ride Start_state (3, 0, 6), reward 2468.0, memory_length 2000, epsilon 0.04380927474017315\n",
      "episode 316, Agent ride Start_state (2, 6, 3), reward 2424.0, memory_length 2000, epsilon 0.04338331533943088\n",
      "episode 317, Agent ride Start_state (4, 13, 6), reward 2627.0, memory_length 2000, epsilon 0.042961594305542104\n",
      "episode 318, Agent ride Start_state (1, 1, 1), reward 2280.0, memory_length 2000, epsilon 0.042544069466051986\n",
      "episode 319, Agent ride Start_state (1, 22, 0), reward 2268.0, memory_length 2000, epsilon 0.04213069906812867\n",
      "episode 320, Agent ride Start_state (2, 18, 1), reward 2405.0, memory_length 2000, epsilon 0.041721441774387844\n",
      "episode 321, Agent ride Start_state (0, 8, 5), reward 2321.0, memory_length 2000, epsilon 0.04131625665875912\n",
      "episode 322, Agent ride Start_state (2, 16, 2), reward 2641.0, memory_length 2000, epsilon 0.04091510320239324\n",
      "episode 323, Agent ride Start_state (4, 1, 4), reward 2689.0, memory_length 2000, epsilon 0.040517941289610324\n",
      "episode 324, Agent ride Start_state (4, 3, 6), reward 2405.0, memory_length 2000, epsilon 0.04012473120388808\n",
      "episode 325, Agent ride Start_state (2, 10, 6), reward 2799.0, memory_length 2000, epsilon 0.03973543362389029\n",
      "episode 326, Agent ride Start_state (2, 19, 0), reward 2571.0, memory_length 2000, epsilon 0.039350009619534505\n",
      "episode 327, Agent ride Start_state (0, 7, 3), reward 2616.0, memory_length 2000, epsilon 0.03896842064809914\n",
      "episode 328, Agent ride Start_state (0, 4, 0), reward 2670.0, memory_length 2000, epsilon 0.03859062855036902\n",
      "episode 329, Agent ride Start_state (4, 19, 4), reward 2574.0, memory_length 2000, epsilon 0.038216595546819596\n",
      "episode 330, Agent ride Start_state (2, 7, 2), reward 2760.0, memory_length 2000, epsilon 0.037846284233838755\n",
      "episode 331, Agent ride Start_state (1, 18, 6), reward 2335.0, memory_length 2000, epsilon 0.03747965757998666\n",
      "episode 332, Agent ride Start_state (3, 3, 6), reward 2619.0, memory_length 2000, epsilon 0.03711667892229237\n",
      "episode 333, Agent ride Start_state (3, 7, 3), reward 2571.0, memory_length 2000, epsilon 0.03675731196258764\n",
      "episode 334, Agent ride Start_state (0, 5, 6), reward 2724.0, memory_length 2000, epsilon 0.036401520763877045\n",
      "episode 335, Agent ride Start_state (2, 20, 3), reward 2665.0, memory_length 2000, epsilon 0.03604926974674418\n",
      "episode 336, Agent ride Start_state (2, 8, 2), reward 2670.0, memory_length 2000, epsilon 0.03570052368579382\n",
      "episode 337, Agent ride Start_state (4, 9, 4), reward 2538.0, memory_length 2000, epsilon 0.03535524770612924\n",
      "episode 338, Agent ride Start_state (4, 15, 5), reward 2686.0, memory_length 2000, epsilon 0.035013407279864746\n",
      "episode 339, Agent ride Start_state (4, 10, 2), reward 2505.0, memory_length 2000, epsilon 0.034674968222672825\n",
      "episode 340, Agent ride Start_state (3, 3, 2), reward 2538.0, memory_length 2000, epsilon 0.03433989669036575\n",
      "episode 341, Agent ride Start_state (1, 13, 6), reward 2411.0, memory_length 2000, epsilon 0.034008159175511046\n",
      "episode 342, Agent ride Start_state (4, 7, 6), reward 2663.0, memory_length 2000, epsilon 0.0336797225040808\n",
      "episode 343, Agent ride Start_state (3, 23, 4), reward 2610.0, memory_length 2000, epsilon 0.033354553832134134\n",
      "episode 344, Agent ride Start_state (0, 20, 6), reward 2380.0, memory_length 2000, epsilon 0.03303262064253291\n",
      "episode 345, Agent ride Start_state (4, 8, 2), reward 2648.0, memory_length 2000, epsilon 0.03271389074168987\n",
      "episode 346, Agent ride Start_state (4, 21, 5), reward 2738.0, memory_length 2000, epsilon 0.032398332256349346\n",
      "episode 347, Agent ride Start_state (3, 23, 1), reward 2553.0, memory_length 2000, epsilon 0.032085913630399795\n",
      "episode 348, Agent ride Start_state (0, 8, 6), reward 2340.0, memory_length 2000, epsilon 0.03177660362171832\n",
      "episode 349, Agent ride Start_state (2, 23, 6), reward 2583.0, memory_length 2000, epsilon 0.031470371299046264\n",
      "episode 350, Agent ride Start_state (0, 17, 1), reward 2626.0, memory_length 2000, epsilon 0.031167186038896184\n",
      "episode 351, Agent ride Start_state (4, 14, 0), reward 2733.0, memory_length 2000, epsilon 0.03086701752248938\n",
      "episode 352, Agent ride Start_state (0, 5, 4), reward 2695.0, memory_length 2000, epsilon 0.030569835732724107\n",
      "episode 353, Agent ride Start_state (4, 1, 3), reward 2544.0, memory_length 2000, epsilon 0.030275610951173707\n",
      "episode 354, Agent ride Start_state (4, 12, 0), reward 2557.0, memory_length 2000, epsilon 0.029984313755114858\n",
      "episode 355, Agent ride Start_state (0, 11, 3), reward 2761.0, memory_length 2000, epsilon 0.029695915014585184\n",
      "episode 356, Agent ride Start_state (1, 13, 0), reward 2503.0, memory_length 2000, epsilon 0.02941038588947032\n",
      "episode 357, Agent ride Start_state (4, 13, 5), reward 2631.0, memory_length 2000, epsilon 0.029127697826619798\n",
      "episode 358, Agent ride Start_state (0, 17, 0), reward 2650.0, memory_length 2000, epsilon 0.02884782255699177\n",
      "episode 359, Agent ride Start_state (2, 14, 1), reward 2600.0, memory_length 2000, epsilon 0.02857073209282604\n",
      "episode 360, Agent ride Start_state (4, 4, 0), reward 2776.0, memory_length 2000, epsilon 0.028296398724845268\n",
      "episode 361, Agent ride Start_state (1, 20, 5), reward 2682.0, memory_length 2000, epsilon 0.028024795019484065\n",
      "episode 362, Agent ride Start_state (0, 22, 2), reward 2637.0, memory_length 2000, epsilon 0.027755893816145537\n",
      "episode 363, Agent ride Start_state (3, 18, 2), reward 2461.0, memory_length 2000, epsilon 0.027489668224485286\n",
      "episode 364, Agent ride Start_state (4, 1, 6), reward 2560.0, memory_length 2000, epsilon 0.027226091621722275\n",
      "episode 365, Agent ride Start_state (1, 9, 3), reward 2655.0, memory_length 2000, epsilon 0.026965137649976594\n",
      "episode 366, Agent ride Start_state (4, 18, 5), reward 2655.0, memory_length 2000, epsilon 0.026706780213633582\n",
      "episode 367, Agent ride Start_state (1, 12, 0), reward 2502.0, memory_length 2000, epsilon 0.026450993476734335\n",
      "episode 368, Agent ride Start_state (0, 2, 2), reward 2671.0, memory_length 2000, epsilon 0.026197751860391985\n",
      "episode 369, Agent ride Start_state (1, 3, 1), reward 2416.0, memory_length 2000, epsilon 0.025947030040233878\n",
      "episode 370, Agent ride Start_state (4, 14, 6), reward 2744.0, memory_length 2000, epsilon 0.02569880294386905\n",
      "episode 371, Agent ride Start_state (1, 1, 5), reward 2715.0, memory_length 2000, epsilon 0.025453045748381017\n",
      "episode 372, Agent ride Start_state (1, 10, 4), reward 2541.0, memory_length 2000, epsilon 0.025209733877845423\n",
      "episode 373, Agent ride Start_state (2, 4, 1), reward 2666.0, memory_length 2000, epsilon 0.024968843000872466\n",
      "episode 374, Agent ride Start_state (0, 5, 4), reward 2420.0, memory_length 2000, epsilon 0.02473034902817369\n",
      "episode 375, Agent ride Start_state (3, 6, 1), reward 2555.0, memory_length 2000, epsilon 0.0244942281101531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 376, Agent ride Start_state (0, 4, 0), reward 2587.0, memory_length 2000, epsilon 0.024260456634522105\n",
      "episode 377, Agent ride Start_state (4, 2, 5), reward 2529.0, memory_length 2000, epsilon 0.024029011223938346\n",
      "episode 378, Agent ride Start_state (4, 8, 4), reward 2470.0, memory_length 2000, epsilon 0.023799868733667878\n",
      "episode 379, Agent ride Start_state (3, 20, 6), reward 2604.0, memory_length 2000, epsilon 0.023573006249270743\n",
      "episode 380, Agent ride Start_state (4, 23, 2), reward 2307.0, memory_length 2000, epsilon 0.023348401084309425\n",
      "episode 381, Agent ride Start_state (2, 17, 1), reward 2483.0, memory_length 2000, epsilon 0.02312603077808028\n",
      "episode 382, Agent ride Start_state (2, 9, 3), reward 2373.0, memory_length 2000, epsilon 0.02290587309336735\n",
      "episode 383, Agent ride Start_state (3, 7, 3), reward 2634.0, memory_length 2000, epsilon 0.022687906014218724\n",
      "episode 384, Agent ride Start_state (1, 0, 5), reward 2520.0, memory_length 2000, epsilon 0.022472107743744835\n",
      "episode 385, Agent ride Start_state (0, 15, 2), reward 2658.0, memory_length 2000, epsilon 0.02225845670193879\n",
      "episode 386, Agent ride Start_state (1, 11, 3), reward 2581.0, memory_length 2000, epsilon 0.022046931523518394\n",
      "episode 387, Agent ride Start_state (1, 21, 0), reward 2603.0, memory_length 2000, epsilon 0.021837511055789505\n",
      "episode 388, Agent ride Start_state (0, 10, 4), reward 2704.0, memory_length 2000, epsilon 0.021630174356530855\n",
      "episode 389, Agent ride Start_state (0, 7, 0), reward 2550.0, memory_length 2000, epsilon 0.021424900691899715\n",
      "episode 390, Agent ride Start_state (3, 22, 1), reward 2587.0, memory_length 2000, epsilon 0.021221669534358587\n",
      "episode 391, Agent ride Start_state (0, 22, 2), reward 2482.0, memory_length 2000, epsilon 0.02102046056062233\n",
      "episode 392, Agent ride Start_state (2, 6, 1), reward 2568.0, memory_length 2000, epsilon 0.020821253649625917\n",
      "episode 393, Agent ride Start_state (0, 10, 5), reward 2173.0, memory_length 2000, epsilon 0.020624028880512228\n",
      "episode 394, Agent ride Start_state (2, 14, 0), reward 2673.0, memory_length 2000, epsilon 0.020428766530640005\n",
      "episode 395, Agent ride Start_state (1, 9, 4), reward 2529.0, memory_length 2000, epsilon 0.020235447073611534\n",
      "episode 396, Agent ride Start_state (1, 7, 6), reward 2520.0, memory_length 2000, epsilon 0.020044051177320027\n",
      "episode 397, Agent ride Start_state (4, 0, 5), reward 2465.0, memory_length 2000, epsilon 0.019854559702016335\n",
      "episode 398, Agent ride Start_state (2, 1, 6), reward 2568.0, memory_length 2000, epsilon 0.01966695369839504\n",
      "episode 399, Agent ride Start_state (3, 9, 1), reward 2415.0, memory_length 2000, epsilon 0.019481214405699422\n",
      "episode 400, Agent ride Start_state (1, 10, 6), reward 2542.0, memory_length 2000, epsilon 0.019297323249845445\n",
      "episode 401, Agent ride Start_state (4, 10, 1), reward 2558.0, memory_length 2000, epsilon 0.019115261841564275\n",
      "episode 402, Agent ride Start_state (3, 20, 5), reward 2566.0, memory_length 2000, epsilon 0.01893501197456335\n",
      "episode 403, Agent ride Start_state (4, 22, 4), reward 2434.0, memory_length 2000, epsilon 0.018756555623705783\n",
      "episode 404, Agent ride Start_state (4, 4, 0), reward 2337.0, memory_length 2000, epsilon 0.01857987494320777\n",
      "episode 405, Agent ride Start_state (0, 6, 0), reward 2643.0, memory_length 2000, epsilon 0.018404952264854023\n",
      "episode 406, Agent ride Start_state (4, 14, 5), reward 2826.0, memory_length 2000, epsilon 0.01823177009623092\n",
      "episode 407, Agent ride Start_state (3, 15, 4), reward 2592.0, memory_length 2000, epsilon 0.01806031111897731\n",
      "episode 408, Agent ride Start_state (0, 17, 0), reward 2681.0, memory_length 2000, epsilon 0.017890558187052576\n",
      "episode 409, Agent ride Start_state (0, 0, 1), reward 2635.0, memory_length 2000, epsilon 0.017722494325022053\n",
      "episode 410, Agent ride Start_state (4, 3, 5), reward 2702.0, memory_length 2000, epsilon 0.017556102726359494\n",
      "episode 411, Agent ride Start_state (1, 16, 3), reward 2756.0, memory_length 2000, epsilon 0.017391366751766352\n",
      "episode 412, Agent ride Start_state (3, 8, 4), reward 2730.0, memory_length 2000, epsilon 0.017228269927507922\n",
      "episode 413, Agent ride Start_state (1, 3, 2), reward 2635.0, memory_length 2000, epsilon 0.017066795943765846\n",
      "episode 414, Agent ride Start_state (0, 1, 4), reward 2724.0, memory_length 2000, epsilon 0.016906928653007188\n",
      "episode 415, Agent ride Start_state (3, 20, 5), reward 2485.0, memory_length 2000, epsilon 0.016748652068369632\n",
      "episode 416, Agent ride Start_state (0, 1, 0), reward 2663.0, memory_length 2000, epsilon 0.016591950362062846\n",
      "episode 417, Agent ride Start_state (3, 12, 5), reward 2699.0, memory_length 2000, epsilon 0.016436807863785607\n",
      "episode 418, Agent ride Start_state (4, 13, 5), reward 2686.0, memory_length 2000, epsilon 0.016283209059158792\n",
      "episode 419, Agent ride Start_state (2, 21, 1), reward 2695.0, memory_length 2000, epsilon 0.016131138588173933\n",
      "episode 420, Agent ride Start_state (1, 21, 5), reward 2672.0, memory_length 2000, epsilon 0.015980581243657227\n",
      "episode 421, Agent ride Start_state (4, 14, 4), reward 2668.0, memory_length 2000, epsilon 0.015831521969748744\n",
      "episode 422, Agent ride Start_state (2, 11, 0), reward 2713.0, memory_length 2000, epsilon 0.015683945860396883\n",
      "episode 423, Agent ride Start_state (1, 12, 1), reward 2416.0, memory_length 2000, epsilon 0.015537838157867707\n",
      "episode 424, Agent ride Start_state (1, 21, 5), reward 2644.0, memory_length 2000, epsilon 0.015393184251269239\n",
      "episode 425, Agent ride Start_state (3, 1, 1), reward 2706.0, memory_length 2000, epsilon 0.015249969675090257\n",
      "episode 426, Agent ride Start_state (1, 20, 5), reward 2715.0, memory_length 2000, epsilon 0.015108180107753798\n",
      "episode 427, Agent ride Start_state (0, 0, 3), reward 2665.0, memory_length 2000, epsilon 0.014967801370184958\n",
      "episode 428, Agent ride Start_state (1, 6, 6), reward 2478.0, memory_length 2000, epsilon 0.01482881942439302\n",
      "episode 429, Agent ride Start_state (0, 13, 5), reward 2659.0, memory_length 2000, epsilon 0.01469122037206758\n",
      "episode 430, Agent ride Start_state (4, 18, 0), reward 2537.0, memory_length 2000, epsilon 0.014554990453188733\n",
      "episode 431, Agent ride Start_state (4, 9, 0), reward 2565.0, memory_length 2000, epsilon 0.014420116044651057\n",
      "episode 432, Agent ride Start_state (1, 11, 4), reward 2667.0, memory_length 2000, epsilon 0.014286583658901324\n",
      "episode 433, Agent ride Start_state (1, 19, 0), reward 2349.0, memory_length 2000, epsilon 0.014154379942589671\n",
      "episode 434, Agent ride Start_state (1, 9, 0), reward 2613.0, memory_length 2000, epsilon 0.014023491675234298\n",
      "episode 435, Agent ride Start_state (0, 18, 4), reward 2730.0, memory_length 2000, epsilon 0.013893905767899381\n",
      "episode 436, Agent ride Start_state (4, 11, 0), reward 2595.0, memory_length 2000, epsilon 0.013765609261886226\n",
      "episode 437, Agent ride Start_state (4, 16, 1), reward 2605.0, memory_length 2000, epsilon 0.013638589327437299\n",
      "episode 438, Agent ride Start_state (4, 2, 1), reward 2717.0, memory_length 2000, epsilon 0.013512833262453311\n",
      "episode 439, Agent ride Start_state (4, 23, 2), reward 2613.0, memory_length 2000, epsilon 0.013388328491222963\n",
      "episode 440, Agent ride Start_state (4, 11, 1), reward 2607.0, memory_length 2000, epsilon 0.013265062563165366\n",
      "episode 441, Agent ride Start_state (2, 21, 4), reward 2658.0, memory_length 2000, epsilon 0.013143023151585019\n",
      "episode 442, Agent ride Start_state (0, 16, 1), reward 2815.0, memory_length 2000, epsilon 0.013022198052439052\n",
      "episode 443, Agent ride Start_state (3, 6, 5), reward 2735.0, memory_length 2000, epsilon 0.012902575183116858\n",
      "episode 444, Agent ride Start_state (4, 18, 0), reward 2502.0, memory_length 2000, epsilon 0.012784142581231811\n",
      "episode 445, Agent ride Start_state (2, 0, 0), reward 2393.0, memory_length 2000, epsilon 0.012666888403425048\n",
      "episode 446, Agent ride Start_state (0, 14, 1), reward 2727.0, memory_length 2000, epsilon 0.012550800924181066\n",
      "episode 447, Agent ride Start_state (3, 15, 1), reward 2505.0, memory_length 2000, epsilon 0.012435868534655205\n",
      "episode 448, Agent ride Start_state (2, 1, 3), reward 2630.0, memory_length 2000, epsilon 0.012322079741512719\n",
      "episode 449, Agent ride Start_state (4, 2, 2), reward 2467.0, memory_length 2000, epsilon 0.012209423165779495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 450, Agent ride Start_state (3, 12, 6), reward 2600.0, memory_length 2000, epsilon 0.012097887541704065\n",
      "episode 451, Agent ride Start_state (3, 5, 4), reward 2560.0, memory_length 2000, epsilon 0.011987461715631073\n",
      "episode 452, Agent ride Start_state (3, 2, 5), reward 2698.0, memory_length 2000, epsilon 0.011878134644885886\n",
      "episode 453, Agent ride Start_state (3, 18, 5), reward 2787.0, memory_length 2000, epsilon 0.011769895396670341\n",
      "episode 454, Agent ride Start_state (1, 18, 3), reward 2649.0, memory_length 2000, epsilon 0.011662733146969403\n",
      "episode 455, Agent ride Start_state (0, 7, 6), reward 2468.0, memory_length 2000, epsilon 0.011556637179468802\n",
      "episode 456, Agent ride Start_state (3, 15, 0), reward 2737.0, memory_length 2000, epsilon 0.011451596884483366\n",
      "episode 457, Agent ride Start_state (0, 16, 4), reward 2528.0, memory_length 2000, epsilon 0.011347601757896082\n",
      "episode 458, Agent ride Start_state (3, 23, 5), reward 2541.0, memory_length 2000, epsilon 0.011244641400107617\n",
      "episode 459, Agent ride Start_state (3, 1, 2), reward 2588.0, memory_length 2000, epsilon 0.011142705514996392\n",
      "episode 460, Agent ride Start_state (1, 4, 1), reward 2610.0, memory_length 2000, epsilon 0.011041783908888943\n",
      "episode 461, Agent ride Start_state (3, 23, 1), reward 2580.0, memory_length 2000, epsilon 0.010941866489540573\n",
      "episode 462, Agent ride Start_state (4, 0, 1), reward 2511.0, memory_length 2000, epsilon 0.010842943265126071\n",
      "episode 463, Agent ride Start_state (1, 4, 5), reward 2675.0, memory_length 2000, epsilon 0.01074500434324056\n",
      "episode 464, Agent ride Start_state (4, 0, 2), reward 2678.0, memory_length 2000, epsilon 0.01064803992991024\n",
      "episode 465, Agent ride Start_state (1, 20, 1), reward 2533.0, memory_length 2000, epsilon 0.010552040328612962\n",
      "episode 466, Agent ride Start_state (4, 4, 1), reward 2639.0, memory_length 2000, epsilon 0.010456995939308614\n",
      "episode 467, Agent ride Start_state (1, 22, 3), reward 2562.0, memory_length 2000, epsilon 0.010362897257479051\n",
      "episode 468, Agent ride Start_state (1, 22, 0), reward 2501.0, memory_length 2000, epsilon 0.010269734873177679\n",
      "episode 469, Agent ride Start_state (4, 8, 0), reward 2596.0, memory_length 2000, epsilon 0.01017749947008842\n",
      "episode 470, Agent ride Start_state (3, 9, 5), reward 2524.0, memory_length 2000, epsilon 0.010086181824594118\n",
      "episode 471, Agent ride Start_state (0, 15, 4), reward 2645.0, memory_length 2000, epsilon 0.009995772804854124\n",
      "episode 472, Agent ride Start_state (4, 2, 2), reward 2545.0, memory_length 2000, epsilon 0.009906263369891113\n",
      "episode 473, Agent ride Start_state (3, 23, 2), reward 2609.0, memory_length 2000, epsilon 0.009817644568686997\n",
      "episode 474, Agent ride Start_state (3, 14, 5), reward 2376.0, memory_length 2000, epsilon 0.009729907539287819\n",
      "episode 475, Agent ride Start_state (4, 23, 0), reward 2527.0, memory_length 2000, epsilon 0.009643043507917514\n",
      "episode 476, Agent ride Start_state (3, 21, 5), reward 2366.0, memory_length 2000, epsilon 0.009557043788100562\n",
      "episode 477, Agent ride Start_state (1, 5, 4), reward 2060.0, memory_length 2000, epsilon 0.009471899779793305\n",
      "episode 478, Agent ride Start_state (1, 6, 6), reward 2600.0, memory_length 2000, epsilon 0.009387602968523978\n",
      "episode 479, Agent ride Start_state (4, 8, 4), reward 2703.0, memory_length 2000, epsilon 0.009304144924541194\n",
      "episode 480, Agent ride Start_state (4, 8, 3), reward 2503.0, memory_length 2000, epsilon 0.00922151730197101\n",
      "episode 481, Agent ride Start_state (3, 1, 4), reward 2644.0, memory_length 2000, epsilon 0.009139711837982303\n",
      "episode 482, Agent ride Start_state (3, 3, 4), reward 2627.0, memory_length 2000, epsilon 0.009058720351960516\n",
      "episode 483, Agent ride Start_state (3, 22, 4), reward 2636.0, memory_length 2000, epsilon 0.008978534744689546\n",
      "episode 484, Agent ride Start_state (2, 21, 3), reward 2609.0, memory_length 2000, epsilon 0.008899146997541848\n",
      "episode 485, Agent ride Start_state (4, 2, 3), reward 2424.0, memory_length 2000, epsilon 0.008820549171676541\n",
      "episode 486, Agent ride Start_state (4, 12, 4), reward 2548.0, memory_length 2000, epsilon 0.008742733407245556\n",
      "episode 487, Agent ride Start_state (3, 11, 6), reward 2415.0, memory_length 2000, epsilon 0.008665691922607594\n",
      "episode 488, Agent ride Start_state (1, 8, 4), reward 2460.0, memory_length 2000, epsilon 0.00858941701354999\n",
      "episode 489, Agent ride Start_state (1, 19, 6), reward 2439.0, memory_length 2000, epsilon 0.008513901052518277\n",
      "episode 490, Agent ride Start_state (3, 17, 2), reward 2636.0, memory_length 2000, epsilon 0.008439136487853414\n",
      "episode 491, Agent ride Start_state (3, 15, 1), reward 2676.0, memory_length 2000, epsilon 0.008365115843036643\n",
      "episode 492, Agent ride Start_state (2, 2, 3), reward 2698.0, memory_length 2000, epsilon 0.008291831715941795\n",
      "episode 493, Agent ride Start_state (0, 10, 4), reward 2566.0, memory_length 2000, epsilon 0.008219276778095086\n",
      "episode 494, Agent ride Start_state (4, 4, 6), reward 2482.0, memory_length 2000, epsilon 0.008147443773942265\n",
      "episode 495, Agent ride Start_state (0, 6, 2), reward 2545.0, memory_length 2000, epsilon 0.008076325520123067\n",
      "episode 496, Agent ride Start_state (2, 10, 5), reward 2571.0, memory_length 2000, epsilon 0.008005914904752838\n",
      "episode 497, Agent ride Start_state (0, 17, 5), reward 2540.0, memory_length 2000, epsilon 0.007936204886711368\n",
      "episode 498, Agent ride Start_state (4, 20, 6), reward 2571.0, memory_length 2000, epsilon 0.007867188494938754\n",
      "episode 499, Agent ride Start_state (3, 5, 6), reward 2676.0, memory_length 2000, epsilon 0.0077988588277383124\n",
      "episode 500, Agent ride Start_state (4, 9, 5), reward 2376.0, memory_length 2000, epsilon 0.007731209052086381\n",
      "episode 501, Agent ride Start_state (0, 22, 5), reward 2518.0, memory_length 2000, epsilon 0.007664232402949019\n",
      "episode 502, Agent ride Start_state (3, 6, 3), reward 2503.0, memory_length 2000, epsilon 0.007597922182605491\n",
      "episode 503, Agent ride Start_state (1, 23, 6), reward 2457.0, memory_length 2000, epsilon 0.007532271759978514\n",
      "episode 504, Agent ride Start_state (2, 11, 6), reward 2403.0, memory_length 2000, epsilon 0.007467274569971116\n",
      "episode 505, Agent ride Start_state (2, 14, 4), reward 2546.0, memory_length 2000, epsilon 0.007402924112810127\n",
      "episode 506, Agent ride Start_state (4, 15, 4), reward 2479.0, memory_length 2000, epsilon 0.007339213953396201\n",
      "episode 507, Agent ride Start_state (4, 4, 3), reward 2520.0, memory_length 2000, epsilon 0.007276137720660316\n",
      "episode 508, Agent ride Start_state (4, 2, 3), reward 2541.0, memory_length 2000, epsilon 0.0072136891069266304\n",
      "episode 509, Agent ride Start_state (2, 11, 5), reward 2653.0, memory_length 2000, epsilon 0.007151861867281728\n",
      "episode 510, Agent ride Start_state (4, 13, 6), reward 2576.0, memory_length 2000, epsilon 0.007090649818950117\n",
      "episode 511, Agent ride Start_state (4, 7, 1), reward 2592.0, memory_length 2000, epsilon 0.007030046840675965\n",
      "episode 512, Agent ride Start_state (1, 3, 2), reward 2604.0, memory_length 2000, epsilon 0.006970046872110937\n",
      "episode 513, Agent ride Start_state (3, 21, 3), reward 2620.0, memory_length 2000, epsilon 0.006910643913208175\n",
      "episode 514, Agent ride Start_state (4, 13, 3), reward 2695.0, memory_length 2000, epsilon 0.006851832023622287\n",
      "episode 515, Agent ride Start_state (1, 14, 5), reward 2668.0, memory_length 2000, epsilon 0.006793605322115299\n",
      "episode 516, Agent ride Start_state (4, 6, 1), reward 2694.0, memory_length 2000, epsilon 0.006735957985968548\n",
      "episode 517, Agent ride Start_state (4, 16, 4), reward 2590.0, memory_length 2000, epsilon 0.006678884250400375\n",
      "episode 518, Agent ride Start_state (1, 3, 6), reward 2620.0, memory_length 2000, epsilon 0.006622378407989661\n",
      "episode 519, Agent ride Start_state (0, 15, 0), reward 2644.0, memory_length 2000, epsilon 0.006566434808105073\n",
      "episode 520, Agent ride Start_state (4, 13, 2), reward 2565.0, memory_length 2000, epsilon 0.006511047856340011\n",
      "episode 521, Agent ride Start_state (0, 2, 6), reward 2537.0, memory_length 2000, epsilon 0.006456212013953138\n",
      "episode 522, Agent ride Start_state (2, 0, 1), reward 2554.0, memory_length 2000, epsilon 0.006401921797314519\n",
      "episode 523, Agent ride Start_state (2, 18, 5), reward 2543.0, memory_length 2000, epsilon 0.006348171777357243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 524, Agent ride Start_state (4, 2, 3), reward 2591.0, memory_length 2000, epsilon 0.006294956579034532\n",
      "episode 525, Agent ride Start_state (3, 13, 5), reward 2677.0, memory_length 2000, epsilon 0.0062422708807822035\n",
      "episode 526, Agent ride Start_state (1, 20, 5), reward 2461.0, memory_length 2000, epsilon 0.006190109413986526\n",
      "episode 527, Agent ride Start_state (3, 18, 0), reward 2599.0, memory_length 2000, epsilon 0.006138466962457349\n",
      "episode 528, Agent ride Start_state (0, 23, 6), reward 2625.0, memory_length 2000, epsilon 0.006087338361906491\n",
      "episode 529, Agent ride Start_state (2, 23, 6), reward 2637.0, memory_length 2000, epsilon 0.006036718499431288\n",
      "episode 530, Agent ride Start_state (4, 16, 1), reward 2609.0, memory_length 2000, epsilon 0.005986602313003307\n",
      "episode 531, Agent ride Start_state (3, 19, 6), reward 2466.0, memory_length 2000, epsilon 0.005936984790962138\n",
      "episode 532, Agent ride Start_state (1, 12, 4), reward 2531.0, memory_length 2000, epsilon 0.005887860971514236\n",
      "episode 533, Agent ride Start_state (2, 19, 6), reward 2563.0, memory_length 2000, epsilon 0.005839225942236718\n",
      "episode 534, Agent ride Start_state (3, 13, 0), reward 2412.0, memory_length 2000, epsilon 0.005791074839586125\n",
      "episode 535, Agent ride Start_state (0, 12, 4), reward 2499.0, memory_length 2000, epsilon 0.005743402848412062\n",
      "episode 536, Agent ride Start_state (3, 18, 5), reward 2449.0, memory_length 2000, epsilon 0.005696205201475693\n",
      "episode 537, Agent ride Start_state (3, 22, 2), reward 2553.0, memory_length 2000, epsilon 0.005649477178972988\n",
      "episode 538, Agent ride Start_state (0, 10, 5), reward 2181.0, memory_length 2000, epsilon 0.005603214108062759\n",
      "episode 539, Agent ride Start_state (2, 6, 3), reward 2477.0, memory_length 2000, epsilon 0.005557411362399361\n",
      "episode 540, Agent ride Start_state (3, 19, 1), reward 2574.0, memory_length 2000, epsilon 0.005512064361670053\n",
      "episode 541, Agent ride Start_state (4, 17, 5), reward 2403.0, memory_length 2000, epsilon 0.005467168571136984\n",
      "episode 542, Agent ride Start_state (1, 3, 1), reward 2542.0, memory_length 2000, epsilon 0.00542271950118368\n",
      "episode 543, Agent ride Start_state (3, 0, 0), reward 2533.0, memory_length 2000, epsilon 0.005378712706866107\n",
      "episode 544, Agent ride Start_state (3, 22, 0), reward 2221.0, memory_length 2000, epsilon 0.0053351437874681554\n",
      "episode 545, Agent ride Start_state (3, 21, 2), reward 2462.0, memory_length 2000, epsilon 0.005292008386061587\n",
      "episode 546, Agent ride Start_state (4, 23, 2), reward 2608.0, memory_length 2000, epsilon 0.005249302189070311\n",
      "episode 547, Agent ride Start_state (2, 22, 6), reward 2514.0, memory_length 2000, epsilon 0.005207020925839038\n",
      "episode 548, Agent ride Start_state (2, 1, 2), reward 2518.0, memory_length 2000, epsilon 0.005165160368206207\n",
      "episode 549, Agent ride Start_state (2, 20, 2), reward 2562.0, memory_length 2000, epsilon 0.005123716330081181\n",
      "episode 550, Agent ride Start_state (2, 7, 5), reward 2469.0, memory_length 2000, epsilon 0.005082684667025603\n",
      "episode 551, Agent ride Start_state (0, 19, 2), reward 2426.0, memory_length 2000, epsilon 0.005042061275838977\n",
      "episode 552, Agent ride Start_state (3, 21, 6), reward 2474.0, memory_length 2000, epsilon 0.0050018420941483266\n",
      "episode 553, Agent ride Start_state (1, 12, 0), reward 2645.0, memory_length 2000, epsilon 0.004962023100001974\n",
      "episode 554, Agent ride Start_state (3, 0, 6), reward 2519.0, memory_length 2000, epsilon 0.004922600311467319\n",
      "episode 555, Agent ride Start_state (3, 10, 2), reward 2407.0, memory_length 2000, epsilon 0.004883569786232654\n",
      "episode 556, Agent ride Start_state (0, 8, 4), reward 2359.0, memory_length 2000, epsilon 0.004844927621212929\n",
      "episode 557, Agent ride Start_state (4, 0, 3), reward 2417.0, memory_length 2000, epsilon 0.0048066699521594446\n",
      "episode 558, Agent ride Start_state (4, 22, 2), reward 2403.0, memory_length 2000, epsilon 0.0047687929532734125\n",
      "episode 559, Agent ride Start_state (4, 11, 0), reward 2478.0, memory_length 2000, epsilon 0.0047312928368233795\n",
      "episode 560, Agent ride Start_state (0, 7, 2), reward 2688.0, memory_length 2000, epsilon 0.004694165852766446\n",
      "episode 561, Agent ride Start_state (0, 4, 2), reward 2339.0, memory_length 2000, epsilon 0.004657408288373274\n",
      "episode 562, Agent ride Start_state (0, 4, 4), reward 2487.0, memory_length 2000, epsilon 0.00462101646785679\n",
      "episode 563, Agent ride Start_state (3, 5, 1), reward 2541.0, memory_length 2000, epsilon 0.004584986752004616\n",
      "episode 564, Agent ride Start_state (3, 5, 0), reward 2577.0, memory_length 2000, epsilon 0.0045493155378151405\n",
      "episode 565, Agent ride Start_state (4, 6, 6), reward 2645.0, memory_length 2000, epsilon 0.004513999258137216\n",
      "episode 566, Agent ride Start_state (0, 20, 1), reward 2610.0, memory_length 2000, epsilon 0.004479034381313451\n",
      "episode 567, Agent ride Start_state (3, 17, 0), reward 2457.0, memory_length 2000, epsilon 0.004444417410827023\n",
      "episode 568, Agent ride Start_state (4, 15, 1), reward 2591.0, memory_length 2000, epsilon 0.004410144884952035\n",
      "episode 569, Agent ride Start_state (4, 12, 4), reward 2415.0, memory_length 2000, epsilon 0.004376213376407336\n",
      "episode 570, Agent ride Start_state (0, 8, 2), reward 2526.0, memory_length 2000, epsilon 0.0043426194920138\n",
      "episode 571, Agent ride Start_state (3, 22, 2), reward 2652.0, memory_length 2000, epsilon 0.0043093598723549925\n",
      "episode 572, Agent ride Start_state (2, 21, 1), reward 2597.0, memory_length 2000, epsilon 0.00427643119144123\n",
      "episode 573, Agent ride Start_state (4, 2, 2), reward 2604.0, memory_length 2000, epsilon 0.004243830156376976\n",
      "episode 574, Agent ride Start_state (2, 4, 5), reward 2727.0, memory_length 2000, epsilon 0.004211553507031563\n",
      "episode 575, Agent ride Start_state (0, 14, 5), reward 2542.0, memory_length 2000, epsilon 0.004179598015713158\n",
      "episode 576, Agent ride Start_state (3, 12, 3), reward 2686.0, memory_length 2000, epsilon 0.004147960486845997\n",
      "episode 577, Agent ride Start_state (2, 23, 1), reward 2670.0, memory_length 2000, epsilon 0.004116637756650827\n",
      "episode 578, Agent ride Start_state (4, 19, 3), reward 2708.0, memory_length 2000, epsilon 0.004085626692828533\n",
      "episode 579, Agent ride Start_state (3, 21, 4), reward 2716.0, memory_length 2000, epsilon 0.004054924194246884\n",
      "episode 580, Agent ride Start_state (2, 2, 5), reward 2740.0, memory_length 2000, epsilon 0.004024527190630439\n",
      "episode 581, Agent ride Start_state (4, 23, 1), reward 2634.0, memory_length 2000, epsilon 0.003994432642253503\n",
      "episode 582, Agent ride Start_state (2, 20, 4), reward 2704.0, memory_length 2000, epsilon 0.003964637539636163\n",
      "episode 583, Agent ride Start_state (0, 5, 5), reward 2765.0, memory_length 2000, epsilon 0.003935138903243327\n",
      "episode 584, Agent ride Start_state (0, 12, 4), reward 2710.0, memory_length 2000, epsilon 0.0039059337831867714\n",
      "episode 585, Agent ride Start_state (0, 17, 1), reward 2736.0, memory_length 2000, epsilon 0.0038770192589301523\n",
      "episode 586, Agent ride Start_state (3, 6, 0), reward 2730.0, memory_length 2000, epsilon 0.0038483924389969525\n",
      "episode 587, Agent ride Start_state (4, 1, 4), reward 2657.0, memory_length 2000, epsilon 0.003820050460681321\n",
      "episode 588, Agent ride Start_state (2, 1, 2), reward 2449.0, memory_length 2000, epsilon 0.003791990489761807\n",
      "episode 589, Agent ride Start_state (4, 8, 1), reward 2515.0, memory_length 2000, epsilon 0.003764209720217936\n",
      "episode 590, Agent ride Start_state (4, 16, 0), reward 2684.0, memory_length 2000, epsilon 0.0037367053739496\n",
      "episode 591, Agent ride Start_state (4, 11, 6), reward 2603.0, memory_length 2000, epsilon 0.0037094747004992566\n",
      "episode 592, Agent ride Start_state (1, 9, 4), reward 2547.0, memory_length 2000, epsilon 0.003682514976776867\n",
      "episode 593, Agent ride Start_state (4, 2, 4), reward 2655.0, memory_length 2000, epsilon 0.0036558235067875905\n",
      "episode 594, Agent ride Start_state (1, 11, 1), reward 2632.0, memory_length 2000, epsilon 0.003629397621362185\n",
      "episode 595, Agent ride Start_state (4, 14, 0), reward 2645.0, memory_length 2000, epsilon 0.00360323467789009\n",
      "episode 596, Agent ride Start_state (4, 1, 2), reward 2614.0, memory_length 2000, epsilon 0.0035773320600551526\n",
      "episode 597, Agent ride Start_state (0, 14, 5), reward 2744.0, memory_length 2000, epsilon 0.0035516871775740054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 598, Agent ride Start_state (4, 5, 1), reward 2668.0, memory_length 2000, epsilon 0.0035262974659370262\n",
      "episode 599, Agent ride Start_state (4, 12, 5), reward 2744.0, memory_length 2000, epsilon 0.003501160386151898\n",
      "episode 600, Agent ride Start_state (0, 21, 6), reward 2646.0, memory_length 2000, epsilon 0.0034762734244896923\n",
      "episode 601, Agent ride Start_state (4, 11, 2), reward 2698.0, memory_length 2000, epsilon 0.0034516340922335033\n",
      "episode 602, Agent ride Start_state (0, 12, 5), reward 2627.0, memory_length 2000, epsilon 0.0034272399254295705\n",
      "episode 603, Agent ride Start_state (0, 17, 0), reward 2656.0, memory_length 2000, epsilon 0.00340308848464089\n",
      "episode 604, Agent ride Start_state (1, 11, 2), reward 2598.0, memory_length 2000, epsilon 0.003379177354703254\n",
      "episode 605, Agent ride Start_state (0, 11, 2), reward 2685.0, memory_length 2000, epsilon 0.0033555041444837427\n",
      "episode 606, Agent ride Start_state (3, 9, 5), reward 2785.0, memory_length 2000, epsilon 0.003332066486641604\n",
      "episode 607, Agent ride Start_state (0, 12, 6), reward 2682.0, memory_length 2000, epsilon 0.003308862037391527\n",
      "episode 608, Agent ride Start_state (2, 0, 5), reward 2808.0, memory_length 2000, epsilon 0.003285888476269247\n",
      "episode 609, Agent ride Start_state (1, 0, 5), reward 2614.0, memory_length 2000, epsilon 0.0032631435058995076\n",
      "episode 610, Agent ride Start_state (0, 22, 3), reward 2614.0, memory_length 2000, epsilon 0.0032406248517663156\n",
      "episode 611, Agent ride Start_state (4, 14, 0), reward 2782.0, memory_length 2000, epsilon 0.0032183302619854955\n",
      "episode 612, Agent ride Start_state (3, 19, 1), reward 2884.0, memory_length 2000, epsilon 0.0031962575070794887\n",
      "episode 613, Agent ride Start_state (3, 20, 0), reward 2794.0, memory_length 2000, epsilon 0.0031744043797544102\n",
      "episode 614, Agent ride Start_state (2, 20, 1), reward 2709.0, memory_length 2000, epsilon 0.0031527686946793156\n",
      "episode 615, Agent ride Start_state (4, 9, 0), reward 2685.0, memory_length 2000, epsilon 0.0031313482882676705\n",
      "episode 616, Agent ride Start_state (1, 23, 1), reward 2616.0, memory_length 2000, epsilon 0.0031101410184609813\n",
      "episode 617, Agent ride Start_state (4, 15, 2), reward 2748.0, memory_length 2000, epsilon 0.003089144764514595\n",
      "episode 618, Agent ride Start_state (2, 17, 3), reward 2717.0, memory_length 2000, epsilon 0.00306835742678562\n",
      "episode 619, Agent ride Start_state (2, 8, 2), reward 2592.0, memory_length 2000, epsilon 0.003047776926522959\n",
      "episode 620, Agent ride Start_state (3, 4, 0), reward 2612.0, memory_length 2000, epsilon 0.003027401205659438\n",
      "episode 621, Agent ride Start_state (3, 13, 5), reward 2591.0, memory_length 2000, epsilon 0.0030072282266059903\n",
      "episode 622, Agent ride Start_state (0, 7, 1), reward 2749.0, memory_length 2000, epsilon 0.002987255972047898\n",
      "episode 623, Agent ride Start_state (0, 6, 6), reward 2708.0, memory_length 2000, epsilon 0.002967482444743062\n",
      "episode 624, Agent ride Start_state (0, 22, 2), reward 2700.0, memory_length 2000, epsilon 0.0029479056673222754\n",
      "episode 625, Agent ride Start_state (4, 9, 5), reward 2629.0, memory_length 2000, epsilon 0.0029285236820914815\n",
      "episode 626, Agent ride Start_state (4, 20, 2), reward 2641.0, memory_length 2000, epsilon 0.002909334550836005\n",
      "episode 627, Agent ride Start_state (0, 6, 5), reward 2722.0, memory_length 2000, epsilon 0.002890336354626728\n",
      "episode 628, Agent ride Start_state (2, 4, 2), reward 2573.0, memory_length 2000, epsilon 0.0028715271936282007\n",
      "episode 629, Agent ride Start_state (3, 1, 1), reward 2661.0, memory_length 2000, epsilon 0.0028529051869086476\n",
      "episode 630, Agent ride Start_state (0, 17, 2), reward 2716.0, memory_length 2000, epsilon 0.002834468472251878\n",
      "episode 631, Agent ride Start_state (0, 6, 3), reward 2542.0, memory_length 2000, epsilon 0.002816215205971061\n",
      "episode 632, Agent ride Start_state (1, 6, 2), reward 2781.0, memory_length 2000, epsilon 0.0027981435627243605\n",
      "episode 633, Agent ride Start_state (1, 17, 4), reward 2642.0, memory_length 2000, epsilon 0.00278025173533239\n",
      "episode 634, Agent ride Start_state (4, 6, 1), reward 2677.0, memory_length 2000, epsilon 0.002762537934597501\n",
      "episode 635, Agent ride Start_state (3, 10, 2), reward 2797.0, memory_length 2000, epsilon 0.0027450003891248574\n",
      "episode 636, Agent ride Start_state (0, 14, 4), reward 2747.0, memory_length 2000, epsilon 0.0027276373451452984\n",
      "episode 637, Agent ride Start_state (3, 8, 5), reward 2614.0, memory_length 2000, epsilon 0.0027104470663399573\n",
      "episode 638, Agent ride Start_state (3, 12, 5), reward 2681.0, memory_length 2000, epsilon 0.002693427833666627\n",
      "episode 639, Agent ride Start_state (0, 2, 2), reward 2602.0, memory_length 2000, epsilon 0.002676577945187857\n",
      "episode 640, Agent ride Start_state (4, 16, 0), reward 2613.0, memory_length 2000, epsilon 0.00265989571590076\n",
      "episode 641, Agent ride Start_state (2, 5, 1), reward 2667.0, memory_length 2000, epsilon 0.0026433794775685042\n",
      "episode 642, Agent ride Start_state (0, 23, 0), reward 2741.0, memory_length 2000, epsilon 0.002627027578553492\n",
      "episode 643, Agent ride Start_state (4, 22, 4), reward 2662.0, memory_length 2000, epsilon 0.0026108383836521967\n",
      "episode 644, Agent ride Start_state (1, 21, 5), reward 2711.0, memory_length 2000, epsilon 0.002594810273931635\n",
      "episode 645, Agent ride Start_state (2, 11, 3), reward 2595.0, memory_length 2000, epsilon 0.002578941646567481\n",
      "episode 646, Agent ride Start_state (1, 21, 3), reward 2756.0, memory_length 2000, epsilon 0.0025632309146837724\n",
      "episode 647, Agent ride Start_state (2, 19, 6), reward 2581.0, memory_length 2000, epsilon 0.002547676507194229\n",
      "episode 648, Agent ride Start_state (4, 1, 0), reward 2693.0, memory_length 2000, epsilon 0.0025322768686451384\n",
      "episode 649, Agent ride Start_state (1, 23, 6), reward 2730.0, memory_length 2000, epsilon 0.0025170304590598157\n",
      "episode 650, Agent ride Start_state (0, 20, 4), reward 2671.0, memory_length 2000, epsilon 0.002501935753784595\n",
      "episode 651, Agent ride Start_state (1, 14, 5), reward 2597.0, memory_length 2000, epsilon 0.00248699124333637\n",
      "episode 652, Agent ride Start_state (1, 16, 2), reward 2689.0, memory_length 2000, epsilon 0.002472195433251641\n",
      "episode 653, Agent ride Start_state (1, 4, 0), reward 2722.0, memory_length 2000, epsilon 0.002457546843937072\n",
      "episode 654, Agent ride Start_state (2, 23, 2), reward 2729.0, memory_length 2000, epsilon 0.002443044010521523\n",
      "episode 655, Agent ride Start_state (4, 14, 3), reward 2736.0, memory_length 2000, epsilon 0.0024286854827095666\n",
      "episode 656, Agent ride Start_state (3, 15, 4), reward 2767.0, memory_length 2000, epsilon 0.0024144698246364553\n",
      "episode 657, Agent ride Start_state (2, 23, 1), reward 2661.0, memory_length 2000, epsilon 0.002400395614724538\n",
      "episode 658, Agent ride Start_state (4, 12, 5), reward 2628.0, memory_length 2000, epsilon 0.002386461445541093\n",
      "episode 659, Agent ride Start_state (3, 20, 5), reward 2715.0, memory_length 2000, epsilon 0.002372665923657591\n",
      "episode 660, Agent ride Start_state (1, 9, 1), reward 2583.0, memory_length 2000, epsilon 0.002359007669510345\n",
      "episode 661, Agent ride Start_state (2, 16, 5), reward 2664.0, memory_length 2000, epsilon 0.0023454853172625613\n",
      "episode 662, Agent ride Start_state (4, 23, 0), reward 2717.0, memory_length 2000, epsilon 0.002332097514667746\n",
      "episode 663, Agent ride Start_state (4, 22, 2), reward 2805.0, memory_length 2000, epsilon 0.002318842922934482\n",
      "episode 664, Agent ride Start_state (4, 0, 4), reward 2652.0, memory_length 2000, epsilon 0.00230572021659255\n",
      "episode 665, Agent ride Start_state (4, 9, 3), reward 2722.0, memory_length 2000, epsilon 0.002292728083360382\n",
      "episode 666, Agent ride Start_state (1, 3, 0), reward 2626.0, memory_length 2000, epsilon 0.0022798652240138273\n",
      "episode 667, Agent ride Start_state (4, 6, 1), reward 2726.0, memory_length 2000, epsilon 0.0022671303522562316\n",
      "episode 668, Agent ride Start_state (4, 11, 2), reward 2774.0, memory_length 2000, epsilon 0.002254522194589807\n",
      "episode 669, Agent ride Start_state (1, 18, 5), reward 2791.0, memory_length 2000, epsilon 0.002242039490188279\n",
      "episode 670, Agent ride Start_state (4, 18, 5), reward 2773.0, memory_length 2000, epsilon 0.002229680990770808\n",
      "episode 671, Agent ride Start_state (1, 21, 2), reward 2646.0, memory_length 2000, epsilon 0.0022174454604771505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 672, Agent ride Start_state (2, 18, 0), reward 2803.0, memory_length 2000, epsilon 0.0022053316757440823\n",
      "episode 673, Agent ride Start_state (3, 0, 6), reward 2838.0, memory_length 2000, epsilon 0.002193338425183034\n",
      "episode 674, Agent ride Start_state (0, 6, 4), reward 2752.0, memory_length 2000, epsilon 0.002181464509458957\n",
      "episode 675, Agent ride Start_state (1, 21, 6), reward 2754.0, memory_length 2000, epsilon 0.002169708741170383\n",
      "episode 676, Agent ride Start_state (1, 7, 0), reward 2745.0, memory_length 2000, epsilon 0.0021580699447306868\n",
      "episode 677, Agent ride Start_state (4, 2, 0), reward 2758.0, memory_length 2000, epsilon 0.002146546956250524\n",
      "episode 678, Agent ride Start_state (4, 20, 5), reward 2653.0, memory_length 2000, epsilon 0.0021351386234214464\n",
      "episode 679, Agent ride Start_state (3, 21, 4), reward 2694.0, memory_length 2000, epsilon 0.0021238438054006627\n",
      "episode 680, Agent ride Start_state (3, 5, 2), reward 2712.0, memory_length 2000, epsilon 0.0021126613726969584\n",
      "episode 681, Agent ride Start_state (2, 1, 6), reward 2739.0, memory_length 2000, epsilon 0.002101590207057744\n",
      "episode 682, Agent ride Start_state (2, 9, 0), reward 2685.0, memory_length 2000, epsilon 0.0020906292013572313\n",
      "episode 683, Agent ride Start_state (3, 19, 4), reward 2794.0, memory_length 2000, epsilon 0.002079777259485715\n",
      "episode 684, Agent ride Start_state (0, 16, 0), reward 2762.0, memory_length 2000, epsilon 0.0020690332962399645\n",
      "Total time Elapsed for episodes: 1000 training in seconds: 10140.8941924572\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "try:\n",
    "    for episode in range(Episodes):\n",
    "\n",
    "        elapsed_time = 0\n",
    "        score = 0\n",
    "        terminal_state = False\n",
    "        state = env.reset()\n",
    "        start_state = state\n",
    "\n",
    "        while  not terminal_state:\n",
    "            # Write your code here\n",
    "            # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "            action = agent.get_action(state, env, episode)\n",
    "            # 2. Evaluate your reward and next state\n",
    "            reward, next_state, step_duration = env.step(state, action)\n",
    "\n",
    "            elapsed_time += step_duration\n",
    "            # window duration is 30 days, The taxis are electric cars. It can run for 30 days non-stop, i.e., 24*30 hrs. \n",
    "            if(elapsed_time >= total_hours_duration):\n",
    "                terminal_state = True\n",
    "\n",
    "            # 3. Append the experience to the memory\n",
    "            # print(env.action_space.index(action))\n",
    "            action_index = env.action_space.index(action)\n",
    "            agent.append_sample(state, action_index, reward, next_state, terminal_state)\n",
    "\n",
    "            # 4. Train the model by calling function agent.train_model\n",
    "            agent.train_model(env)\n",
    "\n",
    "            # 5. Keep a track of rewards, Q-values, loss\n",
    "            score += reward\n",
    "            state = next_state\n",
    "\n",
    "\n",
    "        # store total reward obtained in this episode\n",
    "        rewards_per_episode.append(score)\n",
    "\n",
    "        # every episode:\n",
    "        print(\"episode {0}, Agent ride Start_state {1}, reward {2}, memory_length {3}, epsilon {4}\".format(episode,\n",
    "                                                                             start_state,\n",
    "                                                                             score,\n",
    "                                                                             len(agent.memory),\n",
    "                                                                             agent.epsilon))\n",
    "        # initialize tracking states\n",
    "        if episode == (tracking_threshold - 1):\n",
    "            initialise_tracking_states()\n",
    "            \n",
    "        # if the mean of scores of last 20 episode is bigger than 96% of max_possible_reward then\n",
    "        # we can stop training\n",
    "        if np.mean(rewards_per_episode[-min(20, len(rewards_per_episode)):]) >= (.95 * max_possible_reward):\n",
    "            save_tracking_states(agent, env)\n",
    "            agent.save_model_weights('./save_model/driver_dqn.h5')\n",
    "            sys.exit(0)\n",
    "            \n",
    "        # save tracking states after every 50 episodes    \n",
    "        if (episode + 1) % 50 == 0:\n",
    "            save_tracking_states(agent, env)\n",
    "            agent.save_model_weights('./save_model/driver_dqn.h5')\n",
    "except:\n",
    "    pass\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Total time Elapsed for episodes: {0} training in seconds: {1}'.format(Episodes, elapsed_time))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {(0, 6, 4): {(0, 3): [11, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
       "             (0, 2, 1): {(0, 4): [11, 3, 3, 1, 1, 3, 3, 3, 2, 3, 3, 3, 2, 2]},\n",
       "             (3,\n",
       "              22,\n",
       "              4): {(2, 4): [16,\n",
       "               15,\n",
       "               5,\n",
       "               6,\n",
       "               6,\n",
       "               15,\n",
       "               15,\n",
       "               15,\n",
       "               15,\n",
       "               16,\n",
       "               6,\n",
       "               15,\n",
       "               16,\n",
       "               15], (0, 4): [16,\n",
       "               15,\n",
       "               5,\n",
       "               6,\n",
       "               6,\n",
       "               15,\n",
       "               15,\n",
       "               15,\n",
       "               15,\n",
       "               16,\n",
       "               6,\n",
       "               15,\n",
       "               16,\n",
       "               15]},\n",
       "             (1,\n",
       "              9,\n",
       "              1): {(4, 0): [16, 6, 5, 6, 5, 20, 5, 5, 5, 1, 20, 5, 5, 1]},\n",
       "             (2,\n",
       "              20,\n",
       "              4): {(3, 2): [11, 9, 11, 11, 9, 9, 11, 11, 9, 11, 9, 11, 12, 9]},\n",
       "             (2,\n",
       "              14,\n",
       "              1): {(2, 4): [11,\n",
       "               9,\n",
       "               11,\n",
       "               11,\n",
       "               9,\n",
       "               11,\n",
       "               11,\n",
       "               12,\n",
       "               9,\n",
       "               11,\n",
       "               12,\n",
       "               11,\n",
       "               12,\n",
       "               12],\n",
       "              (0, 4): [11, 9, 11, 11, 9, 11, 11, 12, 9, 11, 12, 11, 12, 12]},\n",
       "             (2,\n",
       "              13,\n",
       "              4): {(4, 2): [11,\n",
       "               9,\n",
       "               11,\n",
       "               11,\n",
       "               11,\n",
       "               11,\n",
       "               11,\n",
       "               11,\n",
       "               11,\n",
       "               11,\n",
       "               12,\n",
       "               11,\n",
       "               12,\n",
       "               11]},\n",
       "             (4,\n",
       "              23,\n",
       "              6): {(2, 4): [11,\n",
       "               20,\n",
       "               17,\n",
       "               20,\n",
       "               17,\n",
       "               17,\n",
       "               20,\n",
       "               20,\n",
       "               17,\n",
       "               18,\n",
       "               18,\n",
       "               20,\n",
       "               17,\n",
       "               17]},\n",
       "             (3,\n",
       "              22,\n",
       "              6): {(0, 4): [16, 15, 15, 6, 6, 15, 16, 6, 6, 16, 6, 6, 16, 16]},\n",
       "             (1,\n",
       "              9,\n",
       "              2): {(0, 0): [16, 6, 5, 5, 5, 20, 5, 5, 5, 1, 20, 5, 5, 9]},\n",
       "             (1,\n",
       "              11,\n",
       "              3): {(1, 3): [16, 6, 5, 6, 6, 20, 5, 20, 5, 20, 20, 5, 1, 1]},\n",
       "             (0, 19, 4): {(4, 1): [3, 20, 3, 1, 1, 3, 3, 1, 1, 1, 3, 1, 1, 1]},\n",
       "             (1,\n",
       "              23,\n",
       "              6): {(2, 4): [16, 6, 5, 6, 6, 7, 5, 6, 6, 6, 17, 6, 17, 6]}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "States_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save rewards_per_episode\n",
    "save_obj(rewards_per_episode, \"saved_pickle_files/rewards_per_episode\")\n",
    "save_obj(States_track,'saved_pickle_files/States_tracked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "with open('saved_pickle_files/rewards_per_episode.pkl', 'rb') as f:\n",
    "    rewards_per_episode = pickle.load(f)\n",
    "\n",
    "plt.plot(list(range(len(rewards_per_episode))), rewards_per_episode)\n",
    "plt.xlabel(\"episode number\")\n",
    "plt.ylabel(\"reward per episode\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw the plot using data captured through States_track for static states \n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(States_track[(0, 2, 1)][(0, 4)], label = \"[(0, 2, 1)][(0, 4)]\")\n",
    "plt.plot(States_track[(3, 22, 4)][(2, 4)], label = \"[(3, 22, 4)][(2, 4)]\")\n",
    "plt.plot(States_track[(1, 11, 3)][(1, 3)], label = \"[(1, 11, 3)][(1, 3)]\")\n",
    "plt.plot(States_track[(2, 20, 4)][(3, 2)], label = \"[(2, 20, 4)][(3, 2)]\")\n",
    "plt.plot(States_track[(2, 13, 4)][(4, 2)], label = \"[(2, 13, 4)][(4, 2)]\")\n",
    "plt.title('Tracked Data for States')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,1000)\n",
    "epsilon = []\n",
    "for i in range(0,1000):\n",
    "    epsilon.append(0.001 + (1 - 0.001) * np.exp(-0.01*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
